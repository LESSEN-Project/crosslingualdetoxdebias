{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749a749-a795-45e0-95fa-23fd98fac652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lang2vec.lang2vec as l2v\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../mbbq\")\n",
    "from mbbq import detect_answers, get_samples\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465107aa",
   "metadata": {},
   "source": [
    "# Defaults and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    (\"aya-expanse-8b\", \"ayaexpanse\", \"base\", \"instruct\"),\n",
    "    (\"aya-expanse-8b_lora_biasdpo_model\", \"ayaexpanse\", \"biasdpo\", \"instruct\"),\n",
    "    (\"aya-expanse-8b_lora_biassft_model\", \"ayaexpanse\", \"biassft\", \"instruct\"),\n",
    "    (\"aya-expanse-8b_lora_panda_model\", \"ayaexpanse\", \"panda\", \"instruct\"),\n",
    "    (\"aya-expanse-8b_lora_jigsaw_model\", \"ayaexpanse\", \"jigsaw\", \"instruct\"),\n",
    "    (\"aya-expanse-8b_lora_detoxdpo_model\", \"ayaexpanse\", \"detoxdpo\", \"instruct\"),\n",
    "    (\"aya-expanse-8b_lora_detoxsft_model\", \"ayaexpanse\", \"detoxsft\", \"instruct\"),\n",
    "    (\"aya-23-8B\", \"aya\", \"base\", \"instruct\"),\n",
    "    (\"aya-23-8B_lora_biasdpo_model\", \"aya\", \"biasdpo\", \"instruct\"),\n",
    "    (\"aya-23-8B_lora_panda_model\", \"aya\", \"panda\", \"instruct\"),\n",
    "    (\"aya-23-8B_lora_jigsaw_model\", \"aya\", \"jigsaw\", \"instruct\"),\n",
    "    (\"aya-23-8B_lora_detoxdpo_model\", \"aya\", \"detoxdpo\", \"instruct\"),\n",
    "    (\"aya-23-8B_lora_biassft_model\", \"aya\", \"biassft\", \"instruct\"),\n",
    "    (\"aya-23-8B_lora_detoxsft_model\", \"aya\", \"detoxsft\", \"instruct\"),\n",
    "    (\"Mistral-7B-v0.3\", \"mistral0.3\", \"base\", \"base\"),\n",
    "    (\"Mistral-7B-Instruct-v0.3\", \"mistral0.3instruct\", \"base\", \"instruct\"),\n",
    "    (\"Meta-Llama-3-8B\", \"llama3\", \"base\", \"base\"),\n",
    "    (\"Meta-Llama-3-8B-Instruct\", \"llama3instruct\", \"base\", \"instruct\"),\n",
    "    (\"Meta-Llama-3.1-8B\", \"llama3.1\", \"base\", \"base\"),\n",
    "    (\"Meta-Llama-3.1-8B-Instruct\", \"llama3.1instruct\", \"base\", \"instruct\"),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biassft_model\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biassft\",\n",
    "        \"instruct\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxsft_model\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxsft\",\n",
    "        \"instruct\",\n",
    "    ),\n",
    "    (\"Meta-Llama-3.1-8B_lora_biasdpo_model\", \"llama3.1\", \"biasdpo\", \"base\"),\n",
    "    (\"Meta-Llama-3.1-8B_lora_biassft_model\", \"llama3.1\", \"biassft\", \"base\"),\n",
    "    (\"Meta-Llama-3.1-8B_lora_panda_model\", \"llama3.1\", \"panda\", \"base\"),\n",
    "    (\"Meta-Llama-3.1-8B_lora_jigsaw_model\", \"llama3.1\", \"jigsaw\", \"base\"),\n",
    "    (\"Meta-Llama-3.1-8B_lora_detoxdpo_model\", \"llama3.1\", \"detoxdpo\", \"base\"),\n",
    "    (\"Meta-Llama-3.1-8B_lora_detoxsft_model\", \"llama3.1\", \"detoxsft\", \"base\"),\n",
    "    (\"gemma-2-2b\", \"gemma2b\", \"base\", \"base\"),\n",
    "    (\"gemma-2-2b-it\", \"gemma2binstruct\", \"base\", \"instruct\"),\n",
    "    (\"gemma-2-9b\", \"gemma9b\", \"base\", \"base\"),\n",
    "    (\"gemma-2-9b_lora_biasdpo_model\", \"gemma9b\", \"biasdpo\", \"base\"),\n",
    "    (\"gemma-2-9b_lora_biassft_model\", \"gemma9b\", \"biassft\", \"base\"),\n",
    "    (\"gemma-2-9b_lora_panda_model\", \"gemma9b\", \"panda\", \"base\"),\n",
    "    (\"gemma-2-9b_lora_jigsaw_model\", \"gemma9b\", \"jigsaw\", \"base\"),\n",
    "    (\"gemma-2-9b_lora_detoxdpo_model\", \"gemma9b\", \"detoxdpo\", \"base\"),\n",
    "    (\"gemma-2-9b_lora_detoxsft_model\", \"gemma9b\", \"detoxsft\", \"base\"),\n",
    "    (\"gemma-2-9b-it\", \"gemma9binstruct\", \"base\", \"instruct\"),\n",
    "    (\"gemma-2-9b-it_lora_biasdpo_model\", \"gemma9binstruct\", \"biasdpo\", \"instruct\"),\n",
    "    (\"gemma-2-9b-it_lora_biassft_model\", \"gemma9binstruct\", \"biassft\", \"instruct\"),\n",
    "    (\"gemma-2-9b-it_lora_panda_model\", \"gemma9binstruct\", \"panda\", \"instruct\"),\n",
    "    (\"gemma-2-9b-it_lora_jigsaw_model\", \"gemma9binstruct\", \"jigsaw\", \"instruct\"),\n",
    "    (\"gemma-2-9b-it_lora_detoxdpo_model\", \"gemma9binstruct\", \"detoxdpo\", \"instruct\"),\n",
    "    (\"gemma-2-9b-it_lora_detoxsft_model\", \"gemma9binstruct\", \"detoxsft\", \"instruct\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biasd_score(context_cond, labels, target_loc, pred):\n",
    "    if context_cond == \"ambig\":\n",
    "        return 0\n",
    "    elif target_loc == labels and pred == 1:\n",
    "        return 1\n",
    "    elif target_loc == 100:\n",
    "        return 0 \n",
    "    elif target_loc != labels and pred == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_understood_templates(\n",
    "    dicts, languages, models, all_templates, disamb_only=False, amb_only=False\n",
    "):\n",
    "    dicts = copy.deepcopy(dicts)\n",
    "    language_templates = {l: set(all_templates) for l in languages}\n",
    "    model_templates = {m: set(all_templates) for m in models}\n",
    "    for i, dicti in enumerate(dicts):\n",
    "        for model in models:\n",
    "            templates = []\n",
    "            for t in all_templates:\n",
    "                if disamb_only:\n",
    "                    accuracy = (\n",
    "                        dicti[dicti[\"subset\"] == t[0]][dicti[\"q_id\"] == t[1]][\n",
    "                            dicti[\"context_condition\"] == \"disambig\"\n",
    "                        ][\"labels\"]\n",
    "                        == dicti[dicti[\"subset\"] == t[0]][dicti[\"q_id\"] == t[1]][\n",
    "                            dicti[\"context_condition\"] == \"disambig\"\n",
    "                        ][f\"answer_{model}_detected\"]\n",
    "                    ).mean()\n",
    "                elif amb_only:\n",
    "                    accuracy = (\n",
    "                        dicti[dicti[\"subset\"] == t[0]][dicti[\"q_id\"] == t[1]][\n",
    "                            dicti[\"context_condition\"] == \"ambig\"\n",
    "                        ][\"labels\"]\n",
    "                        == dicti[dicti[\"subset\"] == t[0]][dicti[\"q_id\"] == t[1]][\n",
    "                            dicti[\"context_condition\"] == \"ambig\"\n",
    "                        ][f\"answer_{model}_detected\"]\n",
    "                    ).mean()\n",
    "                else:\n",
    "                    accuracy = (\n",
    "                        dicti[dicti[\"subset\"] == t[0]][dicti[\"q_id\"] == t[1]][\"labels\"]\n",
    "                        == dicti[dicti[\"subset\"] == t[0]][dicti[\"q_id\"] == t[1]][\n",
    "                            f\"answer_{model}_detected\"\n",
    "                        ]\n",
    "                    ).mean()\n",
    "                if accuracy > 0.33:\n",
    "                    templates.append(t)\n",
    "            model_templates[model] = model_templates[model].intersection(set(templates))\n",
    "            language_templates[languages[i]] = language_templates[\n",
    "                languages[i]\n",
    "            ].intersection(set(templates))\n",
    "    return language_templates, model_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kobbq_ind_template_friedman(\n",
    "    dicts,\n",
    "    languages,\n",
    "    models,\n",
    "    score,\n",
    "    return_all_results=False,\n",
    "    split_by_subset=False,\n",
    "    templates=None,\n",
    "    verbose=True,\n",
    "):\n",
    "    dicts = copy.deepcopy(dicts)\n",
    "    for i in range(len(dicts)):\n",
    "        dicts[i].drop(dicts[i][dicts[i][\"target_loc\"] == 100].index, inplace=True)\n",
    "        if type(templates) == set:\n",
    "            selected_templates = pd.DataFrame([])\n",
    "            for t in templates:\n",
    "                selected_templates = pd.concat(\n",
    "                    [\n",
    "                        selected_templates,\n",
    "                        dicts[i][dicts[i][\"subset\"] == t[0]][dicts[i][\"q_id\"] == t[1]],\n",
    "                    ]\n",
    "                )\n",
    "            dicts[i] = selected_templates\n",
    "        for model in models:\n",
    "            if score == \"amb accuracy\":\n",
    "                dicts[i][f\"{model}_template_score\"] = (\n",
    "                    dicts[i][f\"answer_{model}_detected\"] == dicts[i][\"labels\"]\n",
    "                )\n",
    "                dicts[i] = dicts[i][dicts[i][\"context_condition\"] == \"ambig\"]\n",
    "            elif score == \"disamb accuracy\":\n",
    "                dicts[i][f\"{model}_template_score\"] = (\n",
    "                    dicts[i][f\"answer_{model}_detected\"] == dicts[i][\"labels\"]\n",
    "                )\n",
    "                dicts[i] = dicts[i][dicts[i][\"context_condition\"] == \"disambig\"]\n",
    "            elif score == \"amb bias\":\n",
    "                dicts[i][f\"{model}_template_score\"] = dicts[i][\n",
    "                    f\"answer_{model}_processed\"\n",
    "                ]\n",
    "                dicts[i] = dicts[i][dicts[i][\"context_condition\"] == \"ambig\"]\n",
    "            elif score == \"disamb bias\":\n",
    "                dicts[i][f\"{model}_template_score\"] = dicts[i].apply(\n",
    "                    lambda x: compute_biasd_score(\n",
    "                        x[\"context_condition\"],\n",
    "                        x[\"labels\"],\n",
    "                        x[\"target_loc\"],\n",
    "                        x[f\"answer_{model}_processed\"],\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                )\n",
    "                dicts[i] = dicts[i][dicts[i][\"context_condition\"] == \"disambig\"]\n",
    "    language_scores = {}\n",
    "    model_scores = {}\n",
    "\n",
    "    for i in range(len(languages)):\n",
    "        scores = dicts[i][\n",
    "            [\"prompt_id\", \"subset\", \"q_id\"]\n",
    "            + [f\"{model}_template_score\" for model in models]\n",
    "        ].set_index([\"prompt_id\"])\n",
    "        for model in models:\n",
    "            model_scores[model] = scores[\n",
    "                [\"subset\", \"q_id\", f\"{model}_template_score\"]\n",
    "            ].reset_index(drop=False)\n",
    "        scores = scores.reset_index(drop=False)\n",
    "        language_scores[languages[i]] = scores\n",
    "\n",
    "    if len(languages) > 1:\n",
    "        final_language_scores = {}\n",
    "        for language1 in languages:\n",
    "            final_language_scores[language1] = (\n",
    "                language_scores[language1]\n",
    "                .groupby([\"subset\", \"q_id\", \"prompt_id\"])[f\"{models[0]}_template_score\"]\n",
    "                .mean()\n",
    "            )\n",
    "        means = []\n",
    "        if split_by_subset:\n",
    "            subset_results = {language: {} for language in languages}\n",
    "        else:\n",
    "            results = {}\n",
    "        for k, v in final_language_scores.items():\n",
    "            if split_by_subset:\n",
    "                v = v.reset_index(drop=False)\n",
    "                subset_data = [\n",
    "                    v[v[\"subset\"] == subset][f\"{models[0]}_template_score\"].to_list()\n",
    "                    for subset in [\n",
    "                        \"Age\",\n",
    "                        \"Disability_status\",\n",
    "                        \"Gender_identity\",\n",
    "                        \"Physical_appearance\",\n",
    "                        \"SES\",\n",
    "                        \"Sexual_orientation\",\n",
    "                    ]\n",
    "                ]\n",
    "                for subset, v_subset in zip(\n",
    "                    [\n",
    "                        \"Age\",\n",
    "                        \"Disability_status\",\n",
    "                        \"Gender_identity\",\n",
    "                        \"Physical_appearance\",\n",
    "                        \"SES\",\n",
    "                        \"Sexual_orientation\",\n",
    "                    ],\n",
    "                    subset_data,\n",
    "                ):\n",
    "                    if not v_subset:\n",
    "                        print(subset, \"nan\")\n",
    "                    else:\n",
    "                        print(\n",
    "                            subset, len(v_subset), np.nanmean(v_subset)\n",
    "                        )\n",
    "                test = scipy.stats.kruskal(\n",
    "                    *[s_data for s_data in subset_data if s_data]\n",
    "                )\n",
    "                print(test)\n",
    "                subset_results[k] = [\n",
    "                    (\n",
    "                        (\n",
    "                            np.nanmean(v_subset),\n",
    "                            scipy.stats.ttest_1samp(v_subset, 0).pvalue < 0.05,\n",
    "                        )\n",
    "                        if v_subset\n",
    "                        else (np.nan, False)\n",
    "                    )\n",
    "                    for v_subset in subset_data\n",
    "                ]\n",
    "                continue\n",
    "            v = v.tolist()\n",
    "            means.append(np.nanmean(v))\n",
    "            t_test = scipy.stats.ttest_1samp(v, 0)\n",
    "            if verbose:\n",
    "                print(k, len(v), np.nanmean(v))\n",
    "                print(t_test)\n",
    "            results[k] = (np.nanmean(v), t_test.pvalue < 0.05)\n",
    "        if not split_by_subset:\n",
    "            test = scipy.stats.kruskal(*list(final_language_scores.values()))\n",
    "            if verbose:\n",
    "                print(test)\n",
    "            if return_all_results:\n",
    "                return final_language_scores\n",
    "            return results\n",
    "        if split_by_subset:\n",
    "            return subset_results\n",
    "\n",
    "    if len(models) > 1:\n",
    "        final_model_scores = {}\n",
    "        for model in models:\n",
    "            final_model_scores[model] = (\n",
    "                model_scores[model]\n",
    "                .groupby([\"subset\", \"q_id\", \"prompt_id\"])[f\"{model}_template_score\"]\n",
    "                .mean()\n",
    "            )\n",
    "        means = []\n",
    "        if split_by_subset:\n",
    "            subset_results = {language: {} for language in languages}\n",
    "        else:\n",
    "            results = {}\n",
    "        for k, v in final_model_scores.items():\n",
    "            if split_by_subset:\n",
    "                v = v.reset_index(drop=False)\n",
    "                subset_data = [\n",
    "                    v[v[\"subset\"] == subset][f\"{model}_template_score\"].to_list()\n",
    "                    for subset in [\n",
    "                        \"Age\",\n",
    "                        \"Disability_status\",\n",
    "                        \"Gender_identity\",\n",
    "                        \"Physical_appearance\",\n",
    "                        \"SES\",\n",
    "                        \"Sexual_orientation\",\n",
    "                    ]\n",
    "                ]\n",
    "                for subset, v_subset in zip(\n",
    "                    [\n",
    "                        \"Age\",\n",
    "                        \"Disability_status\",\n",
    "                        \"Gender_identity\",\n",
    "                        \"Physical_appearance\",\n",
    "                        \"SES\",\n",
    "                        \"Sexual_orientation\",\n",
    "                    ],\n",
    "                    subset_data,\n",
    "                ):\n",
    "                    if not v_subset:\n",
    "                        print(subset, \"nan\")\n",
    "                    else:\n",
    "                        print(\n",
    "                            subset, len(v_subset), np.nanmean(v_subset)\n",
    "                        )\n",
    "                test = scipy.stats.kruskal(\n",
    "                    *[s_data for s_data in subset_data if s_data]\n",
    "                )\n",
    "                print(test)\n",
    "                subset_results[k] = [\n",
    "                    (\n",
    "                        (\n",
    "                            np.nanmean(v_subset),\n",
    "                            scipy.stats.ttest_1samp(v_subset, 0).pvalue < 0.05,\n",
    "                        )\n",
    "                        if v_subset\n",
    "                        else (np.nan, False)\n",
    "                    )\n",
    "                    for v_subset in subset_data\n",
    "                ]\n",
    "                continue\n",
    "            v = v.tolist()\n",
    "            means.append(np.nanmean(v))\n",
    "            t_test = scipy.stats.ttest_1samp(v, 0)\n",
    "            if verbose:\n",
    "                print(k, len(v), np.nanmean(v))\n",
    "                print(t_test)\n",
    "            results[k] = (np.nanmean(v), t_test.pvalue < 0.05)\n",
    "\n",
    "        if not split_by_subset:\n",
    "            test = scipy.stats.kruskal(*list(final_model_scores.values()))\n",
    "            if verbose:\n",
    "                print(test)\n",
    "            if return_all_results:\n",
    "                return final_model_scores\n",
    "            return results\n",
    "        if split_by_subset:\n",
    "            return subset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_corr_with_p(df, method=\"pearson\", add_pval=False):\n",
    "    rho = df.corr(method=method)\n",
    "    corr_method = pearsonr if method == \"pearson\" else spearmanr\n",
    "    pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "    if add_pval:\n",
    "        p = pval.round(2).astype(str).map(lambda x: \" p: \" + x)\n",
    "    else:\n",
    "        p = pval.map(lambda x: \"\".join([\"*\" for t in [0.05, 0.01, 0.001] if x <= t]))\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "        print(rho.round(2).astype(str) + p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb418c",
   "metadata": {},
   "source": [
    "# StereoSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d6134-e598-4bf2-b762-4760695bedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"en\": \"English\",\n",
    "    \"kr\": \"Korean\",\n",
    "}\n",
    "\n",
    "\n",
    "def dict_func():\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"ss_score\": [],\n",
    "    \"lm_score\": [],\n",
    "    \"bias_type\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    if dataset in [\"jigsaw\", \"detoxdpo\", \"detoxsft\"]:\n",
    "        continue\n",
    "    for language in names:\n",
    "        with open(f\"stereoset/{model_name}_{language}_ssresults.pkl\", \"rb\") as infile:\n",
    "            score = pickle.load(infile)\n",
    "        for bias_type in [\"gender\", \"profession\", \"race\", \"religion\", \"overall\"]:\n",
    "            data[\"model\"].append(model)\n",
    "            data[\"dataset\"].append(dataset)\n",
    "            data[\"instruction\"].append(instruct)\n",
    "            data[\"language\"].append(names[language])\n",
    "            data[\"ss_score\"].append(score[\"intrasentence\"][bias_type][\"SS Score\"])\n",
    "            data[\"lm_score\"].append(score[\"intrasentence\"][bias_type][\"LM Score\"])\n",
    "            data[\"bias_type\"].append(bias_type)\n",
    "\n",
    "df_stereoset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stereoset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454608d4",
   "metadata": {},
   "source": [
    "## SS score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bfb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stereoset[df_stereoset[\"bias_type\"] == \"overall\"][\n",
    "    df_stereoset[\"language\"] == \"English\"\n",
    "].groupby([\"model\", \"dataset\"])[\"ss_score\"].sum().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stereoset[df_stereoset[\"bias_type\"] == \"overall\"][\n",
    "    df_stereoset[\"language\"] != \"English\"\n",
    "].groupby(\n",
    "    [\n",
    "        \"model\",\n",
    "        \"dataset\",\n",
    "    ]\n",
    ")[\n",
    "    \"ss_score\"\n",
    "].mean().round(\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stereoset[df_stereoset[\"bias_type\"] == \"overall\"][\n",
    "    df_stereoset[\"language\"] != \"English\"\n",
    "].groupby([\"model\", \"dataset\"])[\"ss_score\"].std(ddof=0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220d111",
   "metadata": {},
   "source": [
    "# CrowSPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"zh\": \"Chinese\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c65d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"ss_score\": [],\n",
    "    \"n_samples\": [],\n",
    "    \"bias_type\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    if dataset in [\"jigsaw\", \"detoxdpo\", \"detoxsft\"]:\n",
    "        continue\n",
    "    for language in names:\n",
    "        with open(f\"crowspairs/{model_name}_{language}_cspresults.pkl\", \"rb\") as infile:\n",
    "            score = pickle.load(infile)\n",
    "        for bias_type in [\n",
    "            \"race-color\",\n",
    "            \"socioeconomic\",\n",
    "            \"gender\",\n",
    "            \"disability\",\n",
    "            \"nationality\",\n",
    "            \"sexual-orientation\",\n",
    "            \"physical-appearance\",\n",
    "            \"religion\",\n",
    "            \"age\",\n",
    "        ]:\n",
    "            data[\"model\"].append(model)\n",
    "            data[\"dataset\"].append(dataset)\n",
    "            data[\"instruction\"].append(instruct)\n",
    "            data[\"language\"].append(names[language])\n",
    "            data[\"ss_score\"].append(score[bias_type][0])\n",
    "            data[\"n_samples\"].append(score[bias_type][1])\n",
    "            data[\"bias_type\"].append(bias_type)\n",
    "\n",
    "df_crowspairs = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowspairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27775eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = {\n",
    "    sorted(list(names.values()))[i]: df_crowspairs.groupby([\"model\", \"dataset\", \"instruction\", \"language\"])[\n",
    "        \"n_samples\"\n",
    "    ]\n",
    "    .sum()\n",
    "    .values[i]\n",
    "    for i in range(len(list(names.values())))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d48f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\":[],\n",
    "    \"language\": [],\n",
    "    \"n_samples\": [],\n",
    "    \"ss_score\": [],\n",
    "    \"bias_type\": [],\n",
    "}\n",
    "for row in (\n",
    "    df_crowspairs.groupby([\"model\", \"dataset\", \"instruction\", \"language\"])\n",
    "    .apply(lambda x: np.average(x.ss_score, weights=x.n_samples))\n",
    "    .reset_index()\n",
    "    .iloc\n",
    "):\n",
    "    new_rows[\"model\"].append(row[\"model\"])\n",
    "    new_rows[\"dataset\"].append(row[\"dataset\"])\n",
    "    new_rows[\"instruction\"].append(row[\"instruction\"])\n",
    "    new_rows[\"language\"].append(row[\"language\"])\n",
    "    new_rows[\"n_samples\"].append(n_samples[row[\"language\"]])\n",
    "    new_rows[\"ss_score\"].append(row[0])\n",
    "    new_rows[\"bias_type\"].append(\"overall\")\n",
    "\n",
    "df_crowspairs = pd.concat(\n",
    "    [df_crowspairs, pd.DataFrame(data=new_rows)], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowspairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600a5e9",
   "metadata": {},
   "source": [
    "## SS Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9196502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowspairs[df_crowspairs[\"bias_type\"] == \"overall\"][\n",
    "    df_crowspairs[\"language\"] == \"English\"\n",
    "].groupby([\"model\", \"dataset\"])[\"ss_score\"].sum().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c60fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowspairs[df_crowspairs[\"bias_type\"] == \"overall\"][\n",
    "    df_crowspairs[\"language\"] != \"English\"\n",
    "].groupby([\"model\", \"dataset\"])[\"ss_score\"].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8784337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowspairs[df_crowspairs[\"bias_type\"] == \"overall\"][\n",
    "    df_crowspairs[\"language\"] != \"English\"\n",
    "].groupby([\"model\", \"dataset\"])[\"ss_score\"].std(ddof=0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce63ac",
   "metadata": {},
   "source": [
    "# MBBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5859ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"aya-23-8B\",\n",
    "    \"aya-23-8Bpanda\",\n",
    "    \"aya-23-8Bbiasdpo\",\n",
    "    \"aya-23-8Bbiassft\",\n",
    "    \"aya-expanse-8b\",\n",
    "    \"aya-expanse-8bpanda\",\n",
    "    \"aya-expanse-8bbiasdpo\",\n",
    "    \"aya-expanse-8bbiassft\",\n",
    "    \"Meta-Llama-3-8B-Instruct\",\n",
    "    \"Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"Meta-Llama-3.1-8B-Instructpanda\",\n",
    "    \"Meta-Llama-3.1-8B-Instructbiasdpo\",\n",
    "    \"Meta-Llama-3.1-8B-Instructbiassft\",\n",
    "    \"Mistral-7B-Instruct-v0.3\",\n",
    "    \"gemma-2-9b-it\",\n",
    "    \"gemma-2-9b-itpanda\",\n",
    "    \"gemma-2-9b-itbiasdpo\",\n",
    "    \"gemma-2-9b-itbiassft\",\n",
    "    \"gemma-2-2b-it\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbbq/trialaya-23-8B_samples_en.pkl\", \"rb\") as infile:\n",
    "    english_samples = pickle.load(infile)\n",
    "\n",
    "english_samples = english_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_samples_en.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    english_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    english_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    english_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]\n",
    "\n",
    "with open(\"mbbq/trialaya-23-8B_control_samples_en.pkl\", \"rb\") as infile:\n",
    "    english_control_samples = pickle.load(infile)\n",
    "\n",
    "english_control_samples = english_control_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_control_samples_en.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    english_control_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    english_control_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    english_control_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbbq/trialaya-23-8B_samples_es.pkl\", \"rb\") as infile:\n",
    "    spanish_samples = pickle.load(infile)\n",
    "\n",
    "spanish_samples = spanish_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_samples_es.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    spanish_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    spanish_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    spanish_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]\n",
    "\n",
    "with open(\"mbbq/trialaya-23-8B_control_samples_es.pkl\", \"rb\") as infile:\n",
    "    spanish_control_samples = pickle.load(infile)\n",
    "\n",
    "spanish_control_samples = spanish_control_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_control_samples_es.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    spanish_control_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    spanish_control_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    spanish_control_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f290f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbbq/trialaya-23-8B_samples_nl.pkl\", \"rb\") as infile:\n",
    "    dutch_samples = pickle.load(infile)\n",
    "\n",
    "dutch_samples = dutch_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_samples_nl.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    dutch_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    dutch_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    dutch_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]\n",
    "\n",
    "with open(\"mbbq/trialaya-23-8B_control_samples_nl.pkl\", \"rb\") as infile:\n",
    "    dutch_control_samples = pickle.load(infile)\n",
    "\n",
    "dutch_control_samples = dutch_control_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_control_samples_nl.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    dutch_control_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    dutch_control_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    dutch_control_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbbq/trialaya-23-8B_samples_tr.pkl\", \"rb\") as infile:\n",
    "    turkish_samples = pickle.load(infile)\n",
    "\n",
    "turkish_samples = turkish_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_samples_tr.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    turkish_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    turkish_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    turkish_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]\n",
    "\n",
    "with open(\"mbbq/trialaya-23-8B_control_samples_tr.pkl\", \"rb\") as infile:\n",
    "    turkish_control_samples = pickle.load(infile)\n",
    "\n",
    "turkish_control_samples = turkish_control_samples.rename(\n",
    "    columns={\n",
    "        \"answer\": \"answer_aya-23-8B\",\n",
    "        \"answer_detected\": \"answer_aya-23-8B_detected\",\n",
    "        \"answer_processed\": \"answer_aya-23-8B_processed\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for model in models[1:]:\n",
    "    with open(f\"mbbq/trial{model}_control_samples_tr.pkl\", \"rb\") as infile:\n",
    "        samples = pickle.load(infile)\n",
    "    turkish_control_samples[f\"answer_{model}\"] = samples[\"answer\"]\n",
    "    turkish_control_samples[f\"answer_{model}_detected\"] = samples[\"answer_detected\"]\n",
    "    turkish_control_samples[f\"answer_{model}_processed\"] = samples[\"answer_processed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98e53f",
   "metadata": {},
   "source": [
    "## Selected templates across languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a3ed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_templates = list(\n",
    "    set(zip(english_control_samples[\"subset\"], english_control_samples[\"q_id\"]))\n",
    ")\n",
    "\n",
    "languages = [\"English\", \"Dutch\", \"Spanish\", \"Turkish\"]\n",
    "\n",
    "language_templates, model_templates = get_understood_templates(\n",
    "    [\n",
    "        dutch_control_samples,\n",
    "        english_control_samples,\n",
    "        spanish_control_samples,\n",
    "        turkish_control_samples,\n",
    "    ],\n",
    "    [\"English\", \"Dutch\", \"Spanish\", \"Turkish\"],\n",
    "    models,\n",
    "    all_templates,\n",
    "    disamb_only=True,\n",
    ")\n",
    "\n",
    "selec_temp_results = {}\n",
    "for score in [\"amb bias\", \"disamb bias\"]:\n",
    "    selec_temp_results[score] = {}\n",
    "    print(score)\n",
    "    for model in models:\n",
    "        print(model, len(model_templates[model]))\n",
    "        results = get_kobbq_ind_template_friedman(\n",
    "            [english_samples, dutch_samples, spanish_samples, turkish_samples],\n",
    "            [\"English\", \"Dutch\", \"Spanish\", \"Turkish\"],\n",
    "            [model],\n",
    "            score=score,\n",
    "            templates=model_templates[model],\n",
    "            verbose=False,\n",
    "        )\n",
    "        selec_temp_results[score][model] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a80ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_templates = list(\n",
    "    set(zip(english_control_samples[\"subset\"], english_control_samples[\"q_id\"]))\n",
    ")\n",
    "\n",
    "languages = [\"English\", \"Dutch\", \"Spanish\", \"Turkish\"]\n",
    "\n",
    "subset_results = {}\n",
    "for score in [\"amb bias\", \"disamb bias\"]:\n",
    "    subset_results[score] = {}\n",
    "    print(score)\n",
    "    for model in models:\n",
    "        print(model, len(model_templates[model]))\n",
    "        results = get_kobbq_ind_template_friedman(\n",
    "            [english_samples, dutch_samples, spanish_samples, turkish_samples],\n",
    "            [\"English\", \"Dutch\", \"Spanish\", \"Turkish\"],\n",
    "            [model],\n",
    "            score=score,\n",
    "            templates=model_templates[model],\n",
    "            split_by_subset=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "        subset_results[score][model] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"bias_type\": [],\n",
    "    \"mbbq_context\": [],\n",
    "    \"bias_score\": [],\n",
    "}\n",
    "\n",
    "model_map = {\n",
    "    \"aya-23-8B\": \"aya\",\n",
    "    \"aya-expanse-8b\": \"ayaexpanse\",\n",
    "    \"Meta-Llama-3-8B-Instruct\": \"llama3instruct\",\n",
    "    \"Meta-Llama-3.1-8B-Instruct\": \"llama3.1instruct\",\n",
    "    \"Mistral-7B-Instruct-v0.3\": \"mistral0.3instruct\",\n",
    "    \"gemma-2-2b-it\": \"gemma2binstruct\",\n",
    "    \"gemma-2-9b-it\": \"gemma9binstruct\",\n",
    "}\n",
    "\n",
    "for entry in selec_temp_results[\"amb bias\"]:\n",
    "    for language in selec_temp_results[\"amb bias\"][entry]:\n",
    "        if \"panda\" in entry:\n",
    "            model = entry.split(\"panda\")[0]\n",
    "            dataset = \"panda\"\n",
    "            instruct = \"instruct\"\n",
    "        elif \"biasdpo\" in entry:\n",
    "            model = entry.split(\"biasdpo\")[0]\n",
    "            dataset = \"biasdpo\"\n",
    "            instruct = \"instruct\"\n",
    "        elif \"jigsaw\" in entry:\n",
    "            model = entry.split(\"jigsaw\")[0]\n",
    "            dataset = \"jigsaw\"\n",
    "            instruct = \"instruct\"\n",
    "        elif \"detoxdpo\" in entry:\n",
    "            model = entry.split(\"detoxdpo\")[0]\n",
    "            dataset = \"detoxdpo\"\n",
    "            instruct = \"instruct\"\n",
    "        else:\n",
    "            model = entry\n",
    "            dataset = \"base\"\n",
    "            instruct = \"instruct\"\n",
    "        model = model_map[model]\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(language)\n",
    "        data[\"mbbq_context\"].append(\"amb\")\n",
    "        data[\"bias_type\"].append(\"overall\")\n",
    "        data[\"bias_score\"].append(\n",
    "                selec_temp_results[\"amb bias\"][entry][language][0]\n",
    "        )\n",
    "        for i, bias_type in enumerate(\n",
    "                [\n",
    "                    \"age\",\n",
    "                    \"disability\",\n",
    "                    \"gender\",\n",
    "                    \"physical-appearance\",\n",
    "                    \"socioeconomic\",\n",
    "                    \"sexual-orientation\",\n",
    "                ]\n",
    "            ):\n",
    "                data[\"model\"].append(model)\n",
    "                data[\"dataset\"].append(dataset)\n",
    "                data[\"instruction\"].append(instruct)\n",
    "                data[\"language\"].append(language)\n",
    "                data[\"bias_type\"].append(bias_type)\n",
    "                data[\"mbbq_context\"].append(\"amb\")\n",
    "                data[\"bias_score\"].append(\n",
    "                    subset_results[\"amb bias\"][entry][language][i][0]\n",
    "                )\n",
    "\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(language)\n",
    "        data[\"mbbq_context\"].append(\"disamb\")\n",
    "        data[\"bias_type\"].append(\"overall\")\n",
    "        data[\"bias_score\"].append(\n",
    "                selec_temp_results[\"disamb bias\"][entry][language][0]\n",
    "            )\n",
    "        for i, bias_type in enumerate(\n",
    "                [\n",
    "                    \"age\",\n",
    "                    \"disability\",\n",
    "                    \"gender\",\n",
    "                    \"physical-appearance\",\n",
    "                    \"socioeconomic\",\n",
    "                    \"sexual-orientation\",\n",
    "                ]\n",
    "            ):\n",
    "                data[\"model\"].append(model)\n",
    "                data[\"dataset\"].append(dataset)\n",
    "                data[\"instruction\"].append(instruct)\n",
    "                data[\"language\"].append(language)\n",
    "                data[\"bias_type\"].append(bias_type)\n",
    "                data[\"mbbq_context\"].append(\"disamb\")\n",
    "                data[\"bias_score\"].append(\n",
    "                    subset_results[\"disamb bias\"][entry][language][i][0]\n",
    "                )\n",
    "\n",
    "df_mbbq = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95431654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbbq[df_mbbq[\"bias_type\"] == \"overall\"][df_mbbq[\"mbbq_context\"] == \"amb\"][\n",
    "    df_mbbq[\"language\"] == \"English\"\n",
    "].groupby([\"dataset\", \"model\"])[\"bias_score\"].sum().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0478708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbbq[df_mbbq[\"bias_type\"] == \"overall\"][df_mbbq[\"mbbq_context\"] == \"disamb\"][\n",
    "    df_mbbq[\"language\"] == \"English\"\n",
    "].groupby([\"dataset\", \"model\"])[\"bias_score\"].sum().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e50cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbbq[df_mbbq[\"bias_type\"] == \"overall\"][df_mbbq[\"mbbq_context\"] == \"amb\"][\n",
    "    df_mbbq[\"language\"] != \"English\"\n",
    "].groupby([\"dataset\", \"model\"])[\"bias_score\"].mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbbq[df_mbbq[\"bias_type\"] == \"overall\"][df_mbbq[\"mbbq_context\"] == \"amb\"][\n",
    "    df_mbbq[\"language\"] != \"English\"\n",
    "].groupby([\"dataset\", \"model\"])[\"bias_score\"].std(ddof=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbbq[df_mbbq[\"bias_type\"] == \"overall\"][df_mbbq[\"mbbq_context\"] == \"disamb\"][\n",
    "    df_mbbq[\"language\"] != \"English\"\n",
    "].groupby([\"dataset\", \"model\"])[\"bias_score\"].mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbbq[df_mbbq[\"bias_type\"] == \"overall\"][df_mbbq[\"mbbq_context\"] == \"disamb\"][\n",
    "    df_mbbq[\"language\"] != \"English\"\n",
    "].groupby([\"dataset\", \"model\"])[\"bias_score\"].std(ddof=0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c109e",
   "metadata": {},
   "source": [
    "# Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95584df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"emt\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    if dataset in [\"biasdpo\", \"panda\", \"biassft\"]:\n",
    "        continue\n",
    "    for language in names:\n",
    "        with open(f\"toxicity/{model_name}_{language}_rtp-lx_lang.pkl\", \"rb\") as infile:\n",
    "            right_language = pickle.load(infile)\n",
    "        with open(\n",
    "            f\"toxicity/{model_name}_{language}_rtp-lx_tox_scores.pkl\", \"rb\"\n",
    "        ) as infile:\n",
    "            toxicity_scores = pickle.load(infile)\n",
    "        data[\"emt\"].append(\n",
    "            np.mean(\n",
    "                np.max(toxicity_scores, axis=1, where=right_language == 1, initial=0)\n",
    "            )\n",
    "        )\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(names[language])\n",
    "\n",
    "df_toxicity = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add66582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toxicity[df_toxicity[\"language\"] == \"English\"].groupby([\"model\", \"dataset\"])[\n",
    "    \"emt\"\n",
    "].sum().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toxicity[df_toxicity[\"language\"] != \"English\"].groupby([\"model\", \"dataset\"])[\n",
    "    \"emt\"\n",
    "].mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toxicity[df_toxicity[\"language\"] != \"English\"].groupby([\"model\", \"dataset\"])[\n",
    "    \"emt\"\n",
    "].std(ddof=0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0acde",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26252617",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"perplexity\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    with open(f\"perplexity/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    for language in score:\n",
    "        if language == \"mt\":\n",
    "            num_sent = 65\n",
    "        else:\n",
    "            num_sent = 100\n",
    "        if len([ppl for ppl in score[language][\"selected\"] if ppl != \"wrong_lang\"]) < num_sent:\n",
    "            continue\n",
    "        if dataset == \"base\":\n",
    "            data[\"perplexity\"].append(\n",
    "                np.nanmedian(\n",
    "                    [ppl for ppl in score[language][\"selected\"] if ppl != \"wrong_lang\"]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            base_name = model_name.replace(f'_lora_{dataset}_model', '')\n",
    "            with open(f\"perplexity/{base_name}_results.pkl\", \"rb\") as infile:\n",
    "                base_score = pickle.load(infile)\n",
    "            row_ids = set(\n",
    "                [\n",
    "                     i\n",
    "                     for i, v in enumerate(score[language][\"selected\"])\n",
    "                     if v != \"wrong_lang\"\n",
    "                 ]\n",
    "            )\n",
    "            base_ids = set(\n",
    "                [\n",
    "                    i\n",
    "                     for i, v in enumerate(base_score[language][\"selected\"])\n",
    "                     if v != \"wrong_lang\"\n",
    "                 ]\n",
    "            )\n",
    "            valid_ids = row_ids.intersection(base_ids)\n",
    "            if len(valid_ids) < num_sent:\n",
    "                continue\n",
    "            data[\"perplexity\"].append(\n",
    "                np.nanmedian([score[language][\"selected\"][i] for i in valid_ids])\n",
    "                - np.nanmedian([base_score[language][\"selected\"][i] for i in valid_ids])\n",
    "            )\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(names[language])\n",
    "\n",
    "df_perplexity = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db12f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2c34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    with pd.option_context(\"display.float_format\", \"{:.1f}\".format):\n",
    "        print(\n",
    "            df_perplexity[df_perplexity[\"language\"] != \"English\"]\n",
    "            .groupby([\"model\", \"dataset\"])[\"perplexity\"]\n",
    "            .mean()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908f7c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    with pd.option_context(\"display.float_format\", \"{:.1f}\".format):\n",
    "        print(\n",
    "            df_perplexity[df_perplexity[\"language\"] != \"English\"]\n",
    "            .groupby([\"model\", \"dataset\"])[\"perplexity\"]\n",
    "            .std(ddof=0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55febb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    with pd.option_context(\"display.float_format\", \"{:.0f}\".format):\n",
    "        print(\n",
    "            df_perplexity[df_perplexity[\"language\"] == \"English\"]\n",
    "            .groupby([\"model\", \"dataset\"])[\"perplexity\"]\n",
    "            .sum()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de642a07",
   "metadata": {},
   "source": [
    "# Global-MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1088a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"acc\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    if instruct != \"instruct\":\n",
    "        continue\n",
    "    for language in names:\n",
    "        for dirpath, dirnames, filenames in os.walk(\n",
    "            f\"global_mmlu/{model_name.split(\"_model\")[0]}_{language}\"\n",
    "        ):\n",
    "            if filenames:\n",
    "                file_name = filenames[0]\n",
    "                break\n",
    "        result = json.load(open(f\"{dirpath}/{file_name}\"))\n",
    "\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(names[language])\n",
    "        data[\"acc\"].append(result[\"results\"][f\"global_mmlu_full_{language}\"][\"acc,none\"] * 100)\n",
    "\n",
    "df_global_mmlu = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fa103",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(df_global_mmlu[df_global_mmlu[\"language\"] == \"English\"].groupby(\n",
    "        [\"model\", \"dataset\"]\n",
    "    )[\"acc\"].sum().round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be58fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(df_global_mmlu[df_global_mmlu[\"language\"] != \"English\"].groupby(\n",
    "        [\"model\", \"dataset\"]\n",
    "    )[\"acc\"].mean().round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8088ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(df_global_mmlu[df_global_mmlu[\"language\"] != \"English\"].groupby(\n",
    "        [\"model\", \"dataset\"]\n",
    "    )[\"acc\"].std(ddof=0).round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58beab8",
   "metadata": {},
   "source": [
    "# Language consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee36a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"lc_acc\": [],\n",
    "    \"lc_lpr\": [],\n",
    "    \"lc_wpr\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    with open(f\"lang_confusion/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    for language in names:\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(names[language])\n",
    "        data[\"lc_acc\"].append(score[(\"tatoeba\", language)][\"acc\"]*100)\n",
    "        data[\"lc_lpr\"].append(score[(\"tatoeba\", language)][\"lpr\"]*100)\n",
    "        if \"wpr\" in score[(\"tatoeba\", language)]:\n",
    "            data[\"lc_wpr\"].append(score[(\"tatoeba\", language)][\"wpr\"]*100)\n",
    "        else:\n",
    "            data[\"lc_wpr\"].append(np.nan)\n",
    "\n",
    "df_lang_confusion = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04760f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(df_lang_confusion[df_lang_confusion[\"language\"] == \"English\"].groupby(\n",
    "        [\"model\", \"dataset\"]\n",
    "    )[\"lc_lpr\"].sum().round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643842f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(df_lang_confusion[df_lang_confusion[\"language\"] != \"English\"].groupby(\n",
    "        [\"model\", \"dataset\"]\n",
    "    )[\"lc_lpr\"].mean().round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad60c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(df_lang_confusion[df_lang_confusion[\"language\"] != \"English\"].groupby(\n",
    "        [\"model\", \"dataset\"]\n",
    "    )[\"lc_lpr\"].std(ddof=0).round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c215a3a",
   "metadata": {},
   "source": [
    "# Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd163322",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799dc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "    \"div_uni\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    with open(f\"diversity/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    for language in names:\n",
    "        if language == \"mt\":\n",
    "            num_sent = 65\n",
    "        else:\n",
    "            num_sent = 100\n",
    "        if (\n",
    "            len([div for div in score[language][\"selected\"] if div != \"wrong_lang\"])\n",
    "            < num_sent\n",
    "        ):\n",
    "            continue\n",
    "        if dataset == \"base\":\n",
    "            data[\"div_uni\"].append(\n",
    "                np.mean(\n",
    "                    [div for div in score[language][\"selected\"] if div != \"wrong_lang\"]\n",
    "                )\n",
    "                * 100\n",
    "            )\n",
    "        else:\n",
    "            base_name = model_name.replace(f\"_lora_{dataset}_model\", \"\")\n",
    "            with open(f\"diversity/{base_name}_results.pkl\", \"rb\") as infile:\n",
    "                base_score = pickle.load(infile)\n",
    "            row_ids = set(\n",
    "                [\n",
    "                    i\n",
    "                    for i, v in enumerate(score[language][\"selected\"])\n",
    "                    if v != \"wrong_lang\"\n",
    "                ]\n",
    "            )\n",
    "            base_ids = set(\n",
    "                [\n",
    "                    i\n",
    "                    for i, v in enumerate(base_score[language][\"selected\"])\n",
    "                    if v != \"wrong_lang\"\n",
    "                ]\n",
    "            )\n",
    "            valid_ids = row_ids.intersection(base_ids)\n",
    "            if len(valid_ids) < num_sent:\n",
    "                continue\n",
    "            data[\"div_uni\"].append(\n",
    "                (\n",
    "                    np.mean([score[language][\"selected\"][i] for i in valid_ids])\n",
    "                    - np.mean([base_score[language][\"selected\"][i] for i in valid_ids])\n",
    "                )\n",
    "                * 100\n",
    "            )\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(names[language])\n",
    "\n",
    "df_diversity = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196812b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61583945",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(\n",
    "        df_diversity[df_diversity[\"language\"] != \"English\"]\n",
    "        .groupby([\"model\", \"dataset\"])[\"div_uni\"]\n",
    "        .mean()\n",
    "        .round(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517dced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(\n",
    "        df_diversity[df_diversity[\"language\"] != \"English\"]\n",
    "        .groupby([\"model\", \"dataset\"])[\"div_uni\"]\n",
    "        .std(ddof=0)\n",
    "        .round(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002aefc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    print(\n",
    "        df_diversity[df_diversity[\"language\"] == \"English\"]\n",
    "        .groupby([\"model\", \"dataset\"])[\"div_uni\"]\n",
    "        .sum()\n",
    "        .round(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa0835",
   "metadata": {},
   "source": [
    "# Create one large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c57184",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"language\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct in file_names:\n",
    "    for language in names:\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"language\"].append(names[language])\n",
    "        \n",
    "df_all_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ed6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fa614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias_results = df_stereoset.merge(\n",
    "    df_crowspairs,\n",
    "    on=[\"model\", \"dataset\", \"instruction\", \"language\", \"bias_type\", \"ss_score\"],\n",
    "    how=\"outer\",\n",
    "    indicator=\"bias_dataset\",\n",
    ").drop(columns=[\"lm_score\", \"n_samples\"])\n",
    "\n",
    "df_bias_results[\"bias_dataset\"] = df_bias_results[\"bias_dataset\"].cat.rename_categories(\n",
    "    {\"left_only\": \"stereoset\", \"right_only\": \"crowspairs\"}\n",
    ")\n",
    "\n",
    "\n",
    "df_mbbq_updated = df_mbbq.rename(\n",
    "    columns={\"bias_score\": \"ss_score\"}\n",
    ")\n",
    "df_mbbq_updated.insert(len(df_mbbq_updated.columns), \"bias_dataset\", \"mbbq\")\n",
    "\n",
    "df_bias_results = df_bias_results.merge(\n",
    "    df_mbbq_updated,\n",
    "    on=[\n",
    "        \"model\",\n",
    "        \"dataset\",\n",
    "        \"instruction\",\n",
    "        \"language\",\n",
    "        \"bias_type\",\n",
    "        \"ss_score\",\n",
    "        \"bias_dataset\",\n",
    "    ],\n",
    "    how=\"outer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f239cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm_results = (\n",
    "    df_diversity.rename(columns={\"div_uni\": \"lm_score\"})\n",
    "    .merge(\n",
    "        df_lang_confusion.drop(columns=[\"lc_wpr\", \"lc_acc\"]).rename(\n",
    "            columns={\"lc_lpr\": \"lm_score\"}\n",
    "        ),\n",
    "        on=[\"model\", \"dataset\", \"instruction\", \"language\", \"lm_score\"],\n",
    "        how=\"outer\",\n",
    "        indicator=\"lm_measure\",\n",
    "    )\n",
    ")\n",
    "\n",
    "df_lm_results[\"lm_measure\"] = df_lm_results[\"lm_measure\"].cat.rename_categories(\n",
    "    {\"left_only\": \"diversity\", \"right_only\": \"language consistency\"}\n",
    ")\n",
    "\n",
    "df_perplexity_updated = df_perplexity.rename(columns={\"perplexity\": \"lm_score\"})\n",
    "df_perplexity_updated[\"lm_score\"] = df_perplexity_updated[\"lm_score\"].mul(-1)\n",
    "df_perplexity_updated.insert(\n",
    "    len(df_perplexity_updated.columns), \"lm_measure\", \"fluency\"\n",
    ")\n",
    "\n",
    "df_lm_results = df_lm_results.merge(\n",
    "    df_perplexity_updated,\n",
    "    on=[\"model\", \"dataset\", \"instruction\", \"language\", \"lm_score\", \"lm_measure\"],\n",
    "    how=\"outer\",\n",
    ")\n",
    "\n",
    "df_global_mmlu_updated = df_global_mmlu.rename(columns={\"acc\": \"lm_score\"})\n",
    "df_global_mmlu_updated.insert(\n",
    "    len(df_global_mmlu_updated.columns), \"lm_measure\", \"language understanding\"\n",
    ")\n",
    "\n",
    "df_lm_results = df_lm_results.merge(\n",
    "    df_global_mmlu_updated,\n",
    "    on=[\"model\", \"dataset\", \"instruction\", \"language\", \"lm_score\", \"lm_measure\"],\n",
    "    how=\"outer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f731256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results = df_all_results.merge(\n",
    "    df_bias_results, on=[\"model\", \"dataset\", \"instruction\", \"language\"], how=\"outer\"\n",
    ")\n",
    "df_all_results = df_all_results.merge(\n",
    "    df_toxicity,\n",
    "    on=[\"model\", \"dataset\", \"instruction\", \"language\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "df_all_results = df_all_results.merge(\n",
    "    df_lm_results,\n",
    "    on=[\n",
    "        \"model\",\n",
    "        \"dataset\",\n",
    "        \"instruction\",\n",
    "        \"language\",\n",
    "    ],\n",
    "    how=\"outer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdde86",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d956e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_all_results)):\n",
    "    model = df_all_results.loc[i, \"model\"]\n",
    "    dataset = df_all_results.loc[i, \"dataset\"]\n",
    "    instruction = df_all_results.loc[i, \"instruction\"]\n",
    "    language = df_all_results.loc[i, \"language\"]\n",
    "    bias_type = df_all_results.loc[i, \"bias_type\"]\n",
    "    mbbq_context = df_all_results.loc[i, \"mbbq_context\"]\n",
    "    bias_dataset = df_all_results.loc[i, \"bias_dataset\"]\n",
    "    lm_measure = df_all_results.loc[i, \"lm_measure\"]\n",
    "    if dataset != \"base\":\n",
    "        for c in [\n",
    "            \"ss_score\",\n",
    "            \"emt\",\n",
    "            \"lm_score\",\n",
    "        ]:\n",
    "            new = df_all_results.loc[i, c]\n",
    "            old = df_all_results[df_all_results[\"model\"] == model][\n",
    "                df_all_results[\"dataset\"] == \"base\"\n",
    "            ][df_all_results[\"instruction\"] == instruction][\n",
    "                df_all_results[\"language\"] == language\n",
    "            ][\n",
    "                df_all_results[\"lm_measure\"] == lm_measure\n",
    "            ]\n",
    "            if not pd.isna(bias_type):\n",
    "                old = old[df_all_results[\"bias_type\"] == bias_type]\n",
    "                old = old[df_all_results[\"bias_dataset\"] == bias_dataset]\n",
    "                if not pd.isna(mbbq_context):\n",
    "                    old = old[df_all_results[\"mbbq_context\"] == mbbq_context]\n",
    "            elif (\n",
    "                len(old) > 1\n",
    "            ):\n",
    "                old = old[df_all_results[\"bias_type\"] == \"overall\"]\n",
    "                if (\n",
    "                    len(old) > 1\n",
    "                    and len(old[df_all_results[\"bias_dataset\"] == \"crowspairs\"]) > 0\n",
    "                ):\n",
    "                    old = old[df_all_results[\"bias_dataset\"] == \"crowspairs\"]\n",
    "                elif (\n",
    "                    len(old) > 1\n",
    "                    and len(old[df_all_results[\"mbbq_context\"] == \"amb\"]) > 0\n",
    "                ):\n",
    "                    old = old[df_all_results[\"mbbq_context\"] == \"amb\"]\n",
    "            print(old)\n",
    "            print(\n",
    "                model,\n",
    "                dataset,\n",
    "                instruction,\n",
    "                language,\n",
    "                bias_type,\n",
    "                bias_dataset,\n",
    "                mbbq_context,\n",
    "                lm_measure,\n",
    "            )\n",
    "            old = old[c].item()\n",
    "            if c != \"lm_score\" or lm_measure not in [\"fluency\", \"diversity\"]:\n",
    "                df_all_results.loc[i, c] = new - old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = {\n",
    "    \"panda\": \"SFT, Panda\",\n",
    "    \"biasdpo\": \"DPO, BiasDPO\",\n",
    "    \"biassft\": \"SFT, BiasDPO\",\n",
    "    \"jigsaw\": \"SFT, Jigsaw\",\n",
    "    \"detoxdpo\": \"DPO, DetoxDPO\",\n",
    "    \"detoxsft\": \"SFT, DetoxDPO\",\n",
    "    \"crowspairs\": \"CrowS-Pairs\",\n",
    "    \"stereoset\": \"StereoSet\",\n",
    "    \"gemma9b\": \"Gemma 2 9B\",\n",
    "    \"llama3\": \"Llama 3\",\n",
    "    \"llama3.1\": \"Llama 3.1\",\n",
    "    \"aya\": \"Aya\",\n",
    "    \"ayaexpanse\": \"Aya Expanse\",\n",
    "    \"llama3instruct\": \"Llama 3 Instruct\",\n",
    "    \"llama3.1instruct\": \"Llama 3.1 Instruct\",\n",
    "    \"gemma9binstruct\": \"Gemma 2 9B IT\",\n",
    "    \"diversity\": \"Diversity\",\n",
    "    \"language consistency\": \"Language\\nconsistency\",\n",
    "    \"language understanding\": \"Question-\\nanswering\",\n",
    "    \"fluency\": \"Fluency\",\n",
    "    \"amb\": \"Ambiguous\",\n",
    "    \"disamb\": \"Disambiguated\",\n",
    "    \"age\": \"Age\",\n",
    "    \"disability\": \"Disability status\",\n",
    "    \"gender\": \"Gender identity\",\n",
    "    \"nationality\": \"Nationality\",\n",
    "    \"physical-appearance\": \"Physical appearance\",\n",
    "    \"profession\": \"Profession\",\n",
    "    \"race-color\": \"Race\",\n",
    "    \"race\": \"Race\",\n",
    "    \"religion\": \"Religion\",\n",
    "    \"sexual-orientation\": \"Sexual Orientation\",\n",
    "    \"socioeconomic\": \"Socio-economic status\",\n",
    "}\n",
    "columns_to_rename = {\n",
    "    \"ss_score\": \"Mean absolute\\nchange in bias score\",\n",
    "    \"bias_dataset\": \"Evaluation dataset\",\n",
    "    \"dataset\": \"Method\",\n",
    "    \"model\": \"Model\",\n",
    "    \"emt\": \"Mean absolute change\\nin toxicity score\",\n",
    "    \"lm_measure\": \"Property\",\n",
    "    \"lm_score\": \"Mean absolute\\nchange in score\",\n",
    "    \"mbbq_context\": \"MBBQ context type\",\n",
    "    \"bias_type\": \"Bias Type\",\n",
    "    \"language\": \"Language\",\n",
    "}\n",
    "col_order = [\n",
    "    \"SFT, Panda\",\n",
    "    \"SFT, BiasDPO\",\n",
    "    \"DPO, BiasDPO\",\n",
    "]\n",
    "tox_col_order = [\n",
    "    \"SFT, Jigsaw\",\n",
    "    \"SFT, DetoxDPO\",\n",
    "    \"DPO, DetoxDPO\",\n",
    "]\n",
    "row_order = [\n",
    "    \"Gemma 9B\",\n",
    "    \"Llama 3\",\n",
    "    \"Llama 3.1\",\n",
    "    \"Aya\",\n",
    "    \"Aya Expanse\",\n",
    "    \"Gemma 9B Instruct\",\n",
    "    \"Llama 3 Instruct\",\n",
    "    \"Llama 3.1 Instruct\",\n",
    "]\n",
    "sns.set(font_scale=6, style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a4605",
   "metadata": {},
   "source": [
    "## General results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564137e",
   "metadata": {},
   "source": [
    "### Non-English, base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])][\n",
    "        df_all_results[\"bias_dataset\"].isin([\"crowspairs\", \"stereoset\"])\n",
    "    ][df_all_results[\"instruction\"] == \"base\"][\n",
    "        df_all_results[\"bias_type\"] == \"overall\"\n",
    "    ][\n",
    "        df_all_results[\"lm_measure\"] == \"diversity\"\n",
    "    ][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    col_order=col_order,\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"Evaluation dataset\",\n",
    "    col=\"Method\",\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot1.set_titles(\"{col_name}\")\n",
    "plot1.figure.savefig(\"figures/fig1.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])][\n",
    "        df_all_results[\"instruction\"] == \"base\"\n",
    "    ][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ][\n",
    "        ~pd.isna(df_all_results[\"emt\"])\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute change\\nin toxicity score\",\n",
    "    col=\"Method\",\n",
    "    col_order=tox_col_order,\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot2.set_titles(\"{col_name}\")\n",
    "plot2.figure.savefig(\"figures/fig2.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\"diversity\", \"language consistency\", \"fluency\", \"language understanding\"]\n",
    "        )\n",
    "    ][~df_all_results[\"model\"].isin([\"mistral0.3\", \"mistral0.3instruct\"])][\n",
    "        df_all_results[\"instruction\"] == \"base\"\n",
    "    ][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    col_order=col_order,\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col=\"Method\",\n",
    "    order=[\n",
    "        \"Gemma 2 9B\",\n",
    "        \"Llama 3.1\",\n",
    "    ],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot3.set_titles(\"{col_name}\")\n",
    "plot3.figure.savefig(\"figures/fig3a.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\n",
    "                \"diversity\",\n",
    "                \"language consistency\",\n",
    "                \"fluency\",\n",
    "            ]\n",
    "        )\n",
    "    ][~df_all_results[\"model\"].isin([\"mistral0.3\", \"mistral0.3instruct\"])][\n",
    "        df_all_results[\"instruction\"] == \"base\"\n",
    "    ][\n",
    "        df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col=\"Method\",\n",
    "    col_order=tox_col_order,\n",
    "    order=[\n",
    "        \"Gemma 2 9B\",\n",
    "        \"Llama 3.1\",\n",
    "    ],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot3.set_titles(\"{col_name}\")\n",
    "plot3.figure.savefig(\"figures/fig3b.pdf\", dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ae5cf",
   "metadata": {},
   "source": [
    "### Non-English, instruction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e33a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot4 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"biasdpo\", \"panda\", \"biassft\"])][\n",
    "        df_all_results[\"bias_dataset\"].isin([\"crowspairs\", \"stereoset\"])\n",
    "    ][df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"bias_type\"] == \"overall\"\n",
    "    ][\n",
    "        df_all_results[\"lm_measure\"] == \"diversity\"\n",
    "    ][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    col_order=col_order,\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"Evaluation dataset\",\n",
    "    col=\"Method\",\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot4.set_xticklabels(rotation=25)\n",
    "plot4.set_titles(\"{col_name}\")\n",
    "plot4.figure.savefig(\"figures/fig4.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb37195",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot5 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])][\n",
    "        df_all_results[\"instruction\"] == \"instruct\"\n",
    "    ][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ][\n",
    "        ~pd.isna(df_all_results[\"emt\"])\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute change\\nin toxicity score\",\n",
    "    col=\"Method\",\n",
    "    col_order=tox_col_order,\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot5.set_xticklabels(rotation=25)\n",
    "plot5.set_titles(\"{col_name}\")\n",
    "plot5.figure.savefig(\"figures/fig5.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot6 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"bias_type\"] == \"overall\"\n",
    "    ][df_all_results[\"bias_dataset\"] == \"mbbq\"][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ]\n",
    "    .sort_values(by=\"mbbq_context\")\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    col_order=col_order,\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"MBBQ context type\",\n",
    "    col=\"Method\",\n",
    "    legend_out=True,\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot6.set_xticklabels(rotation=25)\n",
    "plot6.set_titles(\"{col_name}\")\n",
    "plot6.figure.savefig(\"figures/fig6.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot7 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\n",
    "                \"diversity\",\n",
    "                \"language consistency\",\n",
    "                \"fluency\",\n",
    "                \"language understanding\"\n",
    "            ]\n",
    "        )\n",
    "    ][df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    col_order=col_order,\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col=\"Method\",\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot7.set_xticklabels(rotation=25)\n",
    "plot7.set_titles(\"{col_name}\")\n",
    "sns.move_legend(plot7, \"upper left\", bbox_to_anchor=(0.8, 0.8))\n",
    "plot7.figure.savefig(\"figures/fig7a.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot7 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\"diversity\", \"language consistency\", \"fluency\", \"language understanding\"]\n",
    "        )\n",
    "    ][df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] != \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    col_order=tox_col_order,\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col=\"Method\",\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot7.set_xticklabels(rotation=25)\n",
    "plot7.set_titles(\"{col_name}\")\n",
    "sns.move_legend(plot7, \"upper left\", bbox_to_anchor=(0.8, 0.8))\n",
    "plot7.figure.savefig(\"figures/fig7b.pdf\", bbox_inches=\"tight\", dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06600f4f",
   "metadata": {},
   "source": [
    "### English, base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot8 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])][\n",
    "        df_all_results[\"bias_dataset\"].isin([\"crowspairs\", \"stereoset\"])\n",
    "    ][df_all_results[\"instruction\"] == \"base\"][\n",
    "        df_all_results[\"bias_type\"] == \"overall\"\n",
    "    ][\n",
    "        df_all_results[\"lm_measure\"] == \"diversity\"\n",
    "    ][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .sort_values(by=\"bias_dataset\")\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    col_order=col_order,\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"Evaluation dataset\",\n",
    "    col=\"Method\",\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot8.set_titles(\"{col_name}\")\n",
    "plot8.figure.savefig(\n",
    "    \"figures/fig8.pdf\",\n",
    "    dpi=100,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot9 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])][\n",
    "        df_all_results[\"instruction\"] == \"base\"\n",
    "    ][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute change\\nin toxicity score\",\n",
    "    col=\"Method\",\n",
    "    col_order=tox_col_order,\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot9.set_titles(\"{col_name}\")\n",
    "plot9.figure.savefig(\n",
    "    \"figures/fig9.pdf\",\n",
    "    dpi=100,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot10 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\n",
    "                \"diversity\",\n",
    "                \"language consistency\",\n",
    "                \"fluency\",\n",
    "            ]\n",
    "        )\n",
    "    ][~df_all_results[\"model\"].isin([\"mistral0.3\", \"mistral0.3instruct\"])][\n",
    "        df_all_results[\"instruction\"] == \"base\"\n",
    "    ][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    col_order=col_order,\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col=\"Method\",\n",
    "    order=[\"Gemma 2 9B\", \"Llama 3.1\"],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot10.set_xticklabels([\"Gemma 9B\", \"Llama 3.1\"])\n",
    "plot10.set_titles(\"{col_name}\")\n",
    "plot10.figure.savefig(\"figures/fig10a.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot10 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\n",
    "                \"diversity\",\n",
    "                \"language consistency\",\n",
    "                \"fluency\",\n",
    "            ]\n",
    "        )\n",
    "    ][~df_all_results[\"model\"].isin([\"mistral0.3\", \"mistral0.3instruct\"])][\n",
    "        df_all_results[\"instruction\"] == \"base\"\n",
    "    ][\n",
    "        df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    col_order=tox_col_order,\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col=\"Method\",\n",
    "    order=[\"Gemma 2 9B\", \"Llama 3.1\"],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot10.set_titles(\"{col_name}\")\n",
    "plot10.figure.savefig(\"figures/fig10b.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293b317",
   "metadata": {},
   "source": [
    "### English, instruction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot11 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])][\n",
    "        df_all_results[\"bias_dataset\"].isin([\"crowspairs\", \"stereoset\"])\n",
    "    ][df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"bias_type\"] == \"overall\"\n",
    "    ][\n",
    "        df_all_results[\"lm_measure\"] == \"diversity\"\n",
    "    ][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .sort_values(by=\"bias_dataset\")\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    col_order=col_order,\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"Evaluation dataset\",\n",
    "    col=\"Method\",\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot11.set_titles(\"{col_name}\")\n",
    "plot11.set_xticklabels(rotation=25)\n",
    "plot11.figure.savefig(\"figures/fig11.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot12 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])][\n",
    "        df_all_results[\"instruction\"] == \"instruct\"\n",
    "    ][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute change\\nin toxicity score\",\n",
    "    col=\"Method\",\n",
    "    col_order=tox_col_order,\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot12.set_titles(\"{col_name}\")\n",
    "plot12.set_xticklabels(rotation=25)\n",
    "plot12.figure.savefig(\"figures/fig12.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot13 = sns.catplot(\n",
    "    df_all_results[df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"bias_type\"] == \"overall\"\n",
    "    ][df_all_results[\"bias_dataset\"] == \"mbbq\"][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    hue=\"MBBQ context type\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    col_order=col_order,\n",
    "    col=\"Method\",\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot13.set_titles(\"{col_name}\")\n",
    "plot13.set_xticklabels(rotation=25)\n",
    "plot13.figure.savefig(\"figures/fig13.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c18b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot14 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\"diversity\", \"language consistency\", \"fluency\", \"language understanding\"]\n",
    "        )\n",
    "    ][df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"biassft\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col_order=col_order,\n",
    "    col=\"Method\",\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot14.set_titles(\"{col_name}\")\n",
    "plot14.set_xticklabels(rotation=25)\n",
    "sns.move_legend(plot14, \"upper left\", bbox_to_anchor=(0.8, 0.8))\n",
    "plot14.figure.savefig(\"figures/fig14a.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot14 = sns.catplot(\n",
    "    df_all_results[\n",
    "        df_all_results[\"lm_measure\"].isin(\n",
    "            [\n",
    "                \"diversity\",\n",
    "                \"language consistency\",\n",
    "                \"fluency\",\n",
    "                \"language understanding\"\n",
    "            ]\n",
    "        )\n",
    "    ][df_all_results[\"instruction\"] == \"instruct\"][\n",
    "        df_all_results[\"dataset\"].isin([\"jigsaw\", \"detoxsft\", \"detoxdpo\"])\n",
    "    ][\n",
    "        df_all_results[\"language\"] == \"English\"\n",
    "    ]\n",
    "    .groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"language\", \"lm_measure\"], as_index=False\n",
    "    )\n",
    "    .first()\n",
    "    .reset_index(drop=True)\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    "    kind=\"bar\",\n",
    "    x=\"Model\",\n",
    "    y=\"Mean absolute\\nchange in score\",\n",
    "    hue=\"Property\",\n",
    "    col=\"Method\",\n",
    "    col_order=tox_col_order,\n",
    "    order=[\n",
    "        \"Aya\",\n",
    "        \"Aya Expanse\",\n",
    "        \"Gemma 2 9B IT\",\n",
    "        \"Llama 3.1 Instruct\",\n",
    "    ],\n",
    "    height=15,\n",
    "    aspect=1,\n",
    ")\n",
    "plot14.set_titles(\"{col_name}\")\n",
    "plot14.set_xticklabels(rotation=25)\n",
    "sns.move_legend(plot14, \"upper left\", bbox_to_anchor=(0.8, 0.8))\n",
    "plot14.figure.savefig(\"figures/fig14b.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ae573",
   "metadata": {},
   "source": [
    "## Bias type analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0a0e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=8, style=\"white\")\n",
    "bias_ss = sns.catplot(\n",
    "    x=\"Language\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"Bias Type\",\n",
    "    col=\"Method\",\n",
    "    kind=\"strip\",\n",
    "    size=40,\n",
    "    height=18,\n",
    "    aspect=1.6,\n",
    "    col_order=[\"SFT, Panda\", \"DPO, BiasDPO\"],\n",
    "    data=(\n",
    "        df_all_results[df_all_results[\"bias_type\"] != \"overall\"][\n",
    "            df_all_results[\"model\"] == \"llama3.1instruct\"\n",
    "        ][df_all_results[\"dataset\"] != \"base\"][\n",
    "            df_all_results[\"lm_measure\"] == \"diversity\"\n",
    "        ][\n",
    "            df_all_results[\"dataset\"].isin([\"biasdpo\", \"panda\"])\n",
    "        ][\n",
    "            df_all_results[\"bias_dataset\"] == \"stereoset\"\n",
    "        ]\n",
    "        .replace(to_replace)\n",
    "        .rename(columns=columns_to_rename)\n",
    "    ),\n",
    ")\n",
    "bias_ss.set_titles(\"{col_name}\")\n",
    "bias_ss.refline(y=0, color=\"black\")\n",
    "bias_ss.set_xticklabels(rotation=25)\n",
    "bias_ss.figure.savefig(\"figures/bias_ss.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5bf5ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias_csp = sns.catplot(\n",
    "    x=\"Language\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"Bias Type\",\n",
    "    col=\"Method\",\n",
    "    kind=\"swarm\",\n",
    "    size=40,\n",
    "    height=18,\n",
    "    aspect=1.6,\n",
    "    col_order=[\"SFT, Panda\", \"DPO, BiasDPO\"],\n",
    "    data=df_all_results[df_all_results[\"bias_type\"] != \"overall\"][\n",
    "        df_all_results[\"model\"] == \"llama3.1instruct\"\n",
    "    ][df_all_results[\"dataset\"] != \"base\"][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"bias_dataset\"] == \"crowspairs\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    ")\n",
    "bias_csp.set_titles(\"{col_name}\")\n",
    "bias_csp.refline(y=0, color=\"black\")\n",
    "bias_csp.set_xticklabels(rotation=30)\n",
    "bias_csp.figure.savefig(\"figures/bias_csp.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f56bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias_mbbq = sns.catplot(\n",
    "    x=\"Language\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    hue=\"Bias Type\",\n",
    "    col=\"Method\",\n",
    "    kind=\"strip\",\n",
    "    size=40,\n",
    "    col_order=[\"SFT, Panda\", \"DPO, BiasDPO\"],\n",
    "    height=18,\n",
    "    aspect=1.6,\n",
    "    data=df_all_results[df_all_results[\"bias_type\"] != \"overall\"][\n",
    "        df_all_results[\"model\"] == \"llama3.1instruct\"\n",
    "    ][df_all_results[\"dataset\"] != \"base\"][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"dataset\"].isin([\"biasdpo\", \"panda\"])\n",
    "    ][\n",
    "        df_all_results[\"bias_dataset\"] == \"mbbq\"\n",
    "    ][\n",
    "        df_all_results[\"mbbq_context\"] == \"amb\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename),\n",
    ")\n",
    "bias_mbbq.set_titles(\"{col_name}\")\n",
    "bias_mbbq.refline(y=0, color=\"black\")\n",
    "bias_mbbq.set_xticklabels(rotation=25)\n",
    "bias_mbbq.figure.savefig(\"figures/bias_mbbq.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3b4f0",
   "metadata": {},
   "source": [
    "## Difference across languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2792c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=8, style=\"white\")\n",
    "fig = plt.figure(figsize=(40, 22))\n",
    "plot_data = (\n",
    "    df_all_results[df_all_results[\"bias_type\"] == \"overall\"][\n",
    "        df_all_results[\"dataset\"] != \"base\"\n",
    "    ][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        df_all_results[\"bias_dataset\"] == \"stereoset\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename)\n",
    ")\n",
    "\n",
    "colors = [(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)] + [\n",
    "    ((0.2980392156862745, 0.4470588235294118, 0.6901960784313725))\n",
    "    for language in plot_data[\"Language\"].unique()\n",
    "    if language != \"English\"\n",
    "]\n",
    "\n",
    "lang_ord = [\"English\"] + [\n",
    "    lang for lang in plot_data[\"Language\"].unique() if lang != \"English\"\n",
    "]\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"Language\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    data=plot_data,\n",
    "    palette=colors,\n",
    "    order=lang_ord,\n",
    ")\n",
    "fig.axes[0].set_xticklabels(\n",
    "    df_all_results[df_all_results[\"bias_type\"] == \"overall\"][\n",
    "        df_all_results[\"dataset\"] != \"base\"\n",
    "    ][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        df_all_results[\"bias_dataset\"] == \"stereoset\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename)[\"Language\"]\n",
    "    .unique(),\n",
    "    rotation=30,\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/bias_lang_ss.pdf\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c53d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 22))\n",
    "\n",
    "plot_data = (\n",
    "    df_all_results[df_all_results[\"bias_type\"] == \"overall\"][\n",
    "        df_all_results[\"dataset\"] != \"base\"\n",
    "    ][df_all_results[\"lm_measure\"] == \"diversity\"][\n",
    "        df_all_results[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        df_all_results[\"bias_dataset\"] == \"crowspairs\"\n",
    "    ]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename)\n",
    ")\n",
    "\n",
    "colors = [(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)] + [\n",
    "    ((0.2980392156862745, 0.4470588235294118, 0.6901960784313725))\n",
    "    for language in plot_data[\"Language\"].unique()\n",
    "    if language != \"English\"\n",
    "]\n",
    "\n",
    "lang_ord = [\"English\"] + [\n",
    "    lang for lang in plot_data[\"Language\"].unique() if lang != \"English\"\n",
    "]\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"Language\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    data=plot_data,\n",
    "    order=lang_ord,\n",
    "    palette=colors,\n",
    ")\n",
    "fig.axes[0].set_xticklabels(\n",
    "    lang_ord,\n",
    "    rotation=30,\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/bias_lang_csp.pdf\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0041a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 22))\n",
    "\n",
    "plot_data = (\n",
    "    df_all_results[df_all_results[\"bias_type\"] == \"overall\"][\n",
    "        df_all_results[\"dataset\"] != \"base\"\n",
    "    ][df_all_results[\"dataset\"] == \"panda\"][df_all_results[\"bias_dataset\"] == \"mbbq\"]\n",
    "    .replace(to_replace)\n",
    "    .rename(columns=columns_to_rename)\n",
    ")\n",
    "\n",
    "colors = [(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)] + [\n",
    "    ((0.2980392156862745, 0.4470588235294118, 0.6901960784313725))\n",
    "    for language in plot_data[\"Language\"].unique()\n",
    "    if language != \"English\"\n",
    "]\n",
    "\n",
    "lang_ord = [\"English\"] + [\n",
    "    lang for lang in plot_data[\"Language\"].unique() if lang != \"English\"\n",
    "]\n",
    "\n",
    "bias_lang_mbbq = sns.barplot(\n",
    "    x=\"Language\",\n",
    "    y=\"Mean absolute\\nchange in bias score\",\n",
    "    data=plot_data,\n",
    "    order=lang_ord,\n",
    "    palette=colors,\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/bias_lang_mbbq.pdf\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,25))\n",
    "\n",
    "plot_data = df_all_results[df_all_results[\"dataset\"] != \"base\"][\n",
    "        df_all_results[\"lm_measure\"] == \"diversity\"\n",
    "    ][df_all_results[\"dataset\"] == \"detoxdpo\"][\n",
    "        ~df_all_results[\"language\"].isin([\"Maltese\", \"Catalan\", \"Turkish\"])\n",
    "    ].replace(to_replace).rename(columns=columns_to_rename)\n",
    "\n",
    "colors = [(0.8666666666666667, 0.5176470588235295, 0.3215686274509804)] + [\n",
    "    ((0.2980392156862745, 0.4470588235294118, 0.6901960784313725))\n",
    "    for language in plot_data[\"Language\"].unique()\n",
    "    if language != \"English\"\n",
    "]\n",
    "\n",
    "lang_ord = [\"English\"] + [\n",
    "    lang for lang in plot_data[\"Language\"].unique() if lang != \"English\"\n",
    "]\n",
    "\n",
    "toxic_lang = sns.barplot(\n",
    "    x=\"Language\",\n",
    "    y=\"Mean absolute change\\nin toxicity score\",\n",
    "    data=plot_data,\n",
    "    palette=colors,\n",
    "    order=lang_ord,\n",
    ")\n",
    "fig.axes[0].set_xticklabels(\n",
    "    lang_ord,\n",
    "    rotation=70,\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"figures/toxic_lang.pdf\", dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510e703",
   "metadata": {},
   "source": [
    "# Language features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bde7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dict = {\n",
    "    \"fra\": \"French\",\n",
    "    \"deu\": \"German\",\n",
    "    \"spa\": \"Spanish\",\n",
    "    \"tur\": \"Turkish\",\n",
    "    \"zho\": \"Chinese\",\n",
    "    \"mlt\": \"Maltese\",\n",
    "    \"ita\": \"Italian\",\n",
    "    \"cat\": \"Catalan\",\n",
    "    \"ara\": \"Arabic\",\n",
    "    \"kor\": \"Korean\",\n",
    "    \"ind\": \"Indonesian\",\n",
    "    \"pol\": \"Polish\",\n",
    "    \"por\": \"Portuguese\",\n",
    "    \"jpn\": \"Japanese\",\n",
    "    \"nld\": \"Dutch\",\n",
    "    \"hin\": \"Hindi\",\n",
    "    \"ces\": \"Czech\",\n",
    "    \"rus\": \"Russian\",\n",
    "    \"swe\": \"Swedish\",\n",
    "}\n",
    "lang_features = {\"language\": [], \"feature_type\": [], \"cos_sim\": []}\n",
    "for feature_type in [\n",
    "    \"geo\",\n",
    "    \"fam\",\n",
    "    \"syntax_average\",\n",
    "]:\n",
    "    features = l2v.get_features([\"eng\"] + list(lang_dict.keys()), feature_type)\n",
    "    for lang in lang_dict:\n",
    "        lang_features[\"language\"].append(lang_dict[lang])\n",
    "        lang_features[\"feature_type\"].append(feature_type)\n",
    "        f_lang = np.array(features[lang])\n",
    "        if f_lang.dtype == \"<U2\":\n",
    "            f_lang = f_lang.astype(\"<U16\")\n",
    "        f_lang[f_lang == \"--\"] = \"nan\"\n",
    "        f_lang = f_lang.astype(\"float\")\n",
    "        f_eng = np.array(features[\"eng\"])\n",
    "        f_eng[f_eng == \"--\"] = np.nan\n",
    "        f_eng = f_eng.astype(\"float\")\n",
    "        missing_idx = np.union1d(np.where(np.isnan(f_lang)), np.where(np.isnan(f_eng)))\n",
    "        f_lang = np.delete(f_lang, missing_idx)\n",
    "        f_eng = np.delete(f_eng, missing_idx)\n",
    "        lang_features[\"cos_sim\"].append(\n",
    "            np.dot(f_lang, f_eng) / (np.linalg.norm(f_lang) * np.linalg.norm(f_eng))\n",
    "        )\n",
    "df_lang_features = pd.DataFrame(lang_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21414ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lang_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0c3c2",
   "metadata": {},
   "source": [
    "# Subword overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a04b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_features = {\"language\": [], \"model\": [], \"instruction\": [], \"overlap\": []}\n",
    "lang_dict = {\n",
    "    \"fra_Latn\": \"French\",\n",
    "    \"deu_Latn\": \"German\",\n",
    "    \"spa_Latn\": \"Spanish\",\n",
    "    \"tur_Latn\": \"Turkish\",\n",
    "    \"cat_Latn\": \"Catalan\",\n",
    "    \"ita_Latn\": \"Italian\",\n",
    "    \"mlt_Latn\": \"Maltese\",\n",
    "    \"zho_Hans\": \"Chinese\",\n",
    "    \"kor_Hang\": \"Korean\",\n",
    "    \"arb_Arab\": \"Arabic\",\n",
    "    \"ces_Latn\": \"Czech\",\n",
    "    \"hin_Deva\": \"Hindi\",\n",
    "    \"ind_Latn\": \"Indonesian\",\n",
    "    \"jpn_Jpan\": \"Japanese\",\n",
    "    \"nld_Latn\": \"Dutch\",\n",
    "    \"pol_Latn\": \"Polish\",\n",
    "    \"por_Latn\": \"Portuguese\",\n",
    "    \"rus_Cyrl\": \"Russian\",\n",
    "    \"swe_Latn\": \"Swedish\",\n",
    "}\n",
    "for model_name, model, instruct in [\n",
    "    (\"aya-23-8B\", \"aya\", \"instruct\"),\n",
    "    (\"aya-expanse-8b\", \"ayaexpanse\", \"instruct\"),\n",
    "    (\"Meta-Llama-3.1-8B\", \"llama3.1\", \"base\"),\n",
    "    (\"Meta-Llama-3.1-8B-Instruct\", \"llama3.1instruct\", \"instruct\"),\n",
    "    (\"gemma-2-2b\", \"gemma2b\", \"base\"),\n",
    "    (\"gemma-2-2b-it\", \"gemma2binstruct\", \"instruct\"),\n",
    "    (\"gemma-2-9b\", \"gemma9b\", \"base\"),\n",
    "    (\"gemma-2-9b-it\", \"gemma9binstruct\", \"instruct\"),\n",
    "]:\n",
    "    with open(f\"token_overlap/{model_name}_eng_Latn_tokens.pkl\", \"rb\") as infile:\n",
    "        english_tokens = pickle.load(infile)\n",
    "\n",
    "    for language in [\n",
    "        \"fra_Latn\",\n",
    "        \"deu_Latn\",\n",
    "        \"spa_Latn\",\n",
    "        \"tur_Latn\",\n",
    "        \"cat_Latn\",\n",
    "        \"ita_Latn\",\n",
    "        \"mlt_Latn\",\n",
    "        \"zho_Hans\",\n",
    "        \"kor_Hang\",\n",
    "        \"arb_Arab\",\n",
    "        \"ces_Latn\",\n",
    "        \"hin_Deva\",\n",
    "        \"ind_Latn\",\n",
    "        \"jpn_Jpan\",\n",
    "        \"nld_Latn\",\n",
    "        \"pol_Latn\",\n",
    "        \"por_Latn\",\n",
    "        \"rus_Cyrl\",\n",
    "        \"swe_Latn\",\n",
    "    ]:\n",
    "        with open(f\"token_overlap/{model_name}_{language}_tokens.pkl\", \"rb\") as infile:\n",
    "            lang_tokens = pickle.load(infile)\n",
    "        union = 0\n",
    "        intersection = 0\n",
    "        for i in range(len(english_tokens)):\n",
    "            counter_eng = Counter(english_tokens[i])\n",
    "            counter_lang = Counter(lang_tokens[i])\n",
    "            in_both = sum(\n",
    "                (Counter(english_tokens[i]) & Counter(lang_tokens[i])).values()\n",
    "            )\n",
    "            only_in_one = sum(\n",
    "                (Counter(english_tokens[i]) | Counter(lang_tokens[i])).values()\n",
    "            )\n",
    "            union += only_in_one + in_both\n",
    "            intersection += in_both\n",
    "        overlap_features[\"language\"].append(lang_dict[language])\n",
    "        overlap_features[\"model\"].append(model)\n",
    "        overlap_features[\"instruction\"].append(instruct)\n",
    "        overlap_features[\"overlap\"].append(intersection / union)\n",
    "\n",
    "df_overlap = pd.DataFrame(overlap_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8b4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc21b8",
   "metadata": {},
   "source": [
    "# Bilingual sentence retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"stereoset\": {\n",
    "        \"de\": \"German\",\n",
    "        \"es\": \"Spanish\",\n",
    "        \"fr\": \"French\",\n",
    "        \"tr\": \"Turkish\",\n",
    "        \"en\": \"English\",\n",
    "        \"kr\": \"Korean\",\n",
    "    },\n",
    "    \"crowspairs\": {\n",
    "        \"ar\": \"Arabic\",\n",
    "        \"ca\": \"Catalan\",\n",
    "        \"de\": \"German\",\n",
    "        \"es\": \"Spanish\",\n",
    "        \"fr\": \"French\",\n",
    "        \"it\": \"Italian\",\n",
    "        \"en\": \"English\",\n",
    "        \"mt\": \"Maltese\",\n",
    "        \"zh\": \"Chinese\",\n",
    "    },\n",
    "    \"rtp-lx\": {\n",
    "        \"ar\": \"Arabic\",\n",
    "        \"cs\": \"Czech\",\n",
    "        \"de\": \"German\",\n",
    "        \"es\": \"Spanish\",\n",
    "        \"fr\": \"French\",\n",
    "        \"ko\": \"Korean\",\n",
    "        \"it\": \"Italian\",\n",
    "        \"en\": \"English\",\n",
    "        \"zh\": \"Chinese\",\n",
    "        \"hi\": \"Hindi\",\n",
    "        \"id\": \"Indonesian\",\n",
    "        \"ja\": \"Japanese\",\n",
    "        \"nl\": \"Dutch\",\n",
    "        \"pl\": \"Polish\",\n",
    "        \"pt\": \"Portuguese\",\n",
    "        \"ru\": \"Russian\",\n",
    "        \"sv\": \"Swedish\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilingual_sent_data = {\n",
    "    \"language\": [],\n",
    "    \"model\": [],\n",
    "    \"instruction\": [],\n",
    "    \"dataset\": [],\n",
    "    \"retrieval_acc\": [],\n",
    "}\n",
    "for model_name, model, instruct, datasets in [\n",
    "    (\"aya-23-8B\", \"aya\", \"instruct\", (\"crowspairs\", \"stereoset\", \"rtp-lx\")),\n",
    "    (\"aya-expanse-8b\", \"ayaexpanse\", \"instruct\", (\"crowspairs\", \"stereoset\", \"rtp-lx\")),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"instruct\",\n",
    "        (\"crowspairs\", \"stereoset\", \"rtp-lx\"),\n",
    "    ),\n",
    "    (\"Meta-Llama-3.1-8B\", \"llama3.1\", \"base\", (\"crowspairs\", \"stereoset\", \"rtp-lx\")),\n",
    "    (\"gemma-2-9b\", \"gemma9b\", \"base\", (\"crowspairs\", \"stereoset\", \"rtp-lx\")),\n",
    "    (\n",
    "        \"gemma-2-9b-it\",\n",
    "        \"gemma9binstruct\",\n",
    "        \"instruct\",\n",
    "        (\"crowspairs\", \"stereoset\", \"rtp-lx\"),\n",
    "    ),\n",
    "]:\n",
    "    for dataset in datasets:\n",
    "        with open(\n",
    "            f\"bilingual_sent_retrieval/{dataset}_{model_name}_results.pkl\", \"rb\"\n",
    "        ) as infile:\n",
    "            scores = pickle.load(infile)\n",
    "        for language in scores:\n",
    "            bilingual_sent_data[\"language\"].append(names[dataset][language])\n",
    "            bilingual_sent_data[\"model\"].append(model)\n",
    "            bilingual_sent_data[\"instruction\"].append(instruct)\n",
    "            bilingual_sent_data[\"dataset\"].append(dataset)\n",
    "            bilingual_sent_data[\"retrieval_acc\"].append(scores[language])\n",
    "\n",
    "df_bi_sent_acc = pd.DataFrame(bilingual_sent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bi_sent_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c8fba",
   "metadata": {},
   "source": [
    "# Aya data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e584eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 513758189\n",
    "lang_samples = {\n",
    "    \"Arabic\": 6641429,\n",
    "    \"Catalan\":0,\n",
    "    \"Czech\": 4299946,\n",
    "    \"German\": 5447064,\n",
    "    \"Spanish\": 4499536,\n",
    "    \"French\": 4955862,\n",
    "    \"Korean\": 4161353,\n",
    "    \"Italian\": 4526024,\n",
    "    \"English\": 17838105,\n",
    "    \"Maltese\":0,\n",
    "    \"Turkish\": 4180274,\n",
    "    \"Chinese\": 74972,\n",
    "    \"Hindi\": 4380729,\n",
    "    \"Indonesian\": 4166051,\n",
    "    \"Japanese\": 6813519,\n",
    "    \"Dutch\": 4340523,\n",
    "    \"Polish\": 4452845,\n",
    "    \"Portuguese\": 4407774,\n",
    "    \"Russian\": 4666262,\n",
    "    \"Swedish\":0,\n",
    "}\n",
    "data = {\"language\": [], \"perc_aya_data\": []}\n",
    "for language in lang_samples:\n",
    "    data[\"language\"].append(language)\n",
    "    data[\"perc_aya_data\"].append((lang_samples[language] / n) * 100)\n",
    "\n",
    "aya_dataset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c93fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aya_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "aya_dataset[\n",
    "    aya_dataset[\"language\"].isin(\n",
    "        [\n",
    "            \"Arabic\",\n",
    "            \"Catalan\",\n",
    "            \"Czech\",\n",
    "            \"German\",\n",
    "            \"Spanish\",\n",
    "            \"French\",\n",
    "            \"Korean\",\n",
    "            \"Italian\",\n",
    "            \"English\",\n",
    "            \"Maltese\",\n",
    "            \"Turkish\",\n",
    "            \"Chinese\",\n",
    "            \"Hindi\",\n",
    "            \"Indonesian\",\n",
    "            \"Japanese\",\n",
    "            \"Dutch\",\n",
    "            \"Polish\",\n",
    "            \"Portuguese\",\n",
    "            \"Russian\",\n",
    "            \"Swedish\",\n",
    "        ]\n",
    "    )\n",
    "].sort_values(by=\"perc_aya_data\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130db7d",
   "metadata": {},
   "source": [
    "# CC data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3862bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv from https://commoncrawl.github.io/cc-crawl-statistics/plots/languages\n",
    "df_cc_language = pd.read_csv(\"languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    \"ara\": \"Arabic\",\n",
    "    \"cat\": \"Catalan\",\n",
    "    \"ces\": \"Czech\",\n",
    "    \"deu\": \"German\",\n",
    "    \"spa\": \"Spanish\",\n",
    "    \"fra\": \"French\",\n",
    "    \"kor\": \"Korean\",\n",
    "    \"ita\": \"Italian\",\n",
    "    \"eng\": \"English\",\n",
    "    \"mlt\": \"Maltese\",\n",
    "    \"tur\": \"Turkish\",\n",
    "    \"zho\": \"Chinese\",\n",
    "    \"hin\": \"Hindi\",\n",
    "    \"ind\": \"Indonesian\",\n",
    "    \"jpn\": \"Japanese\",\n",
    "    \"nld\": \"Dutch\",\n",
    "    \"pol\": \"Polish\",\n",
    "    \"por\": \"Portuguese\",\n",
    "    \"rus\": \"Russian\",\n",
    "    \"swe\": \"Swedish\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"CC-MAIN-2024-30\"\n",
    "data = {\"language\": [], \"perc_cc_data\": []}\n",
    "for language in languages:\n",
    "    data[\"language\"].append(languages[language])\n",
    "    data[\"perc_cc_data\"].append(\n",
    "        df_cc_language[df_cc_language[\"crawl\"] == date][\n",
    "            df_cc_language[\"primary_language\"] == language\n",
    "        ][\"%pages/crawl\"].item()\n",
    "    )\n",
    "\n",
    "df_cc_perc = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f1db5",
   "metadata": {},
   "source": [
    "# Prepare for correlations / regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e92d1b",
   "metadata": {},
   "source": [
    "## CrowSPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13117bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasing_csp = df_crowspairs[\n",
    "    df_crowspairs[\"model\"].isin(\n",
    "        [\n",
    "            \"aya\",\n",
    "            \"ayaexpanse\",\n",
    "            \"gemma9b\",\n",
    "            \"gemma9binstruct\",\n",
    "            \"llama3.1\",\n",
    "            \"llama3.1instruct\",\n",
    "        ]\n",
    "    )\n",
    "][df_crowspairs[\"dataset\"].isin([\"base\", \"panda\", \"biasdpo\"])].sort_values(\n",
    "    [\"model\", \"dataset\", \"language\", \"bias_type\"], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(debiasing_csp[\"language\"].unique()) * len(debiasing_csp[\"bias_type\"].unique())\n",
    "\n",
    "debiasing_csp[\"base_ss_score\"] = (\n",
    "    debiasing_csp[debiasing_csp[\"dataset\"] == \"base\"][\"ss_score\"]\n",
    "    .iloc[\n",
    "        [\n",
    "            el\n",
    "            for i in range(\n",
    "                0,\n",
    "                len(debiasing_csp[debiasing_csp[\"dataset\"] == \"base\"]),\n",
    "                n,\n",
    "            )\n",
    "            for el in list(range(i, i + n)) * 4\n",
    "        ]\n",
    "    ]\n",
    "    .reset_index()[\"ss_score\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58929663",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasing_csp[\"bias_mitigation\"] = (\n",
    "    (debiasing_csp[\"ss_score\"] - debiasing_csp[\"base_ss_score\"])\n",
    "    / debiasing_csp[\"base_ss_score\"]\n",
    "    * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7255d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasing_csp = debiasing_csp[debiasing_csp[\"dataset\"] != \"base\"]\n",
    "debiasing_csp = debiasing_csp[debiasing_csp[\"language\"] != \"English\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620327f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasing_csp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a34a1",
   "metadata": {},
   "source": [
    "## Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38949e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detox = df_toxicity[\n",
    "    df_toxicity[\"model\"].isin(\n",
    "        [\n",
    "            \"aya\",\n",
    "            \"ayaexpanse\",\n",
    "            \"llama3.1\",\n",
    "            \"llama3.1instruct\",\n",
    "            \"gemma9b\",\n",
    "            \"gemma9binstruct\",\n",
    "        ]\n",
    "    )\n",
    "].sort_values([\"model\", \"dataset\", \"language\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a13045",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(detox[\"language\"].unique())\n",
    "\n",
    "detox[\"base_emt\"] = (\n",
    "    detox[detox[\"dataset\"] == \"base\"][\"emt\"]\n",
    "    .iloc[\n",
    "        [\n",
    "            el\n",
    "            for i in range(\n",
    "                0,\n",
    "                len(detox[detox[\"dataset\"] == \"base\"]),\n",
    "                n,\n",
    "            )\n",
    "            for el in list(range(i, i + n)) * 4\n",
    "        ]\n",
    "    ]\n",
    "    .reset_index()[\"emt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "detox[\"detoxification\"] = (detox[\"emt\"] - detox[\"base_emt\"]) / detox[\"base_emt\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2471ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "detox = detox[detox[\"dataset\"] != \"base\"]\n",
    "detox = detox[detox[\"language\"] != \"English\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ef44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b85c0",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728de0b",
   "metadata": {},
   "source": [
    "## CrowSPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7b0cc",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasing_csp = pd.merge(debiasing_csp, df_lang_features, how=\"left\", on=\"language\")\n",
    "\n",
    "debiasing_csp = pd.merge(\n",
    "    debiasing_csp, df_overlap, how=\"left\", on=[\"language\", \"model\", \"instruction\"]\n",
    ")\n",
    "\n",
    "debiasing_csp = pd.merge(\n",
    "    debiasing_csp,\n",
    "    df_bi_sent_acc[df_bi_sent_acc[\"dataset\"] == \"crowspairs\"].drop(columns=[\"dataset\"]),\n",
    "    how=\"left\",\n",
    "    on=[\"language\", \"model\", \"instruction\"],\n",
    ")\n",
    "\n",
    "debiasing_csp = pd.merge(debiasing_csp, aya_dataset, how=\"left\", on=\"language\")\n",
    "\n",
    "debiasing_csp = pd.merge(debiasing_csp, df_cc_perc, how=\"left\", on=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d847b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasing_csp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc29aaa",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    debiasing_csp[debiasing_csp[\"bias_type\"] == \"overall\"][\n",
    "        debiasing_csp[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        debiasing_csp[\"model\"].isin(\n",
    "            [\n",
    "                \"aya\",\n",
    "                \"ayaexpanse\",\n",
    "                \"llama3\",\n",
    "                \"llama3.1\",\n",
    "                \"gemma9b\",\n",
    "                \"llama3instruct\",\n",
    "                \"llama3.1instruct\",\n",
    "                \"gemma9binstruct\",\n",
    "            ]\n",
    "        )\n",
    "    ].groupby(\n",
    "        [\"model\", \"feature_type\"]\n",
    "    )[\n",
    "        [\"bias_mitigation\", \"cos_sim\"]\n",
    "    ],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    debiasing_csp[debiasing_csp[\"bias_type\"] == \"overall\"][\n",
    "        debiasing_csp[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        debiasing_csp[\"model\"].isin(\n",
    "            [\n",
    "                \"aya\",\n",
    "                \"ayaexpanse\",\n",
    "                \"llama3\",\n",
    "                \"llama3.1\",\n",
    "                \"gemma9b\",\n",
    "                \"llama3instruct\",\n",
    "                \"llama3.1instruct\",\n",
    "                \"gemma9binstruct\",\n",
    "            ]\n",
    "        )\n",
    "    ].groupby(\n",
    "        [\"model\"]\n",
    "    )[\n",
    "        [\"bias_mitigation\", \"overlap\"]\n",
    "    ],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e641cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    debiasing_csp[debiasing_csp[\"bias_type\"] == \"overall\"][\n",
    "        debiasing_csp[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        debiasing_csp[\"model\"].isin(\n",
    "            [\n",
    "                \"aya\",\n",
    "                \"ayaexpanse\",\n",
    "                \"llama3\",\n",
    "                \"llama3.1\",\n",
    "                \"gemma9b\",\n",
    "                \"llama3instruct\",\n",
    "                \"llama3.1instruct\",\n",
    "                \"gemma9binstruct\",\n",
    "            ]\n",
    "        )\n",
    "    ].groupby(\n",
    "        [\"model\"]\n",
    "    )[\n",
    "        [\"retrieval_acc\", \"bias_mitigation\"]\n",
    "    ],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a53c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    debiasing_csp[debiasing_csp[\"bias_type\"] == \"overall\"][\n",
    "        debiasing_csp[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        debiasing_csp[\"model\"].isin(\n",
    "            [\n",
    "                \"aya\",\n",
    "                \"ayaexpanse\",\n",
    "                \"llama3\",\n",
    "                \"llama3.1\",\n",
    "                \"gemma9b\",\n",
    "                \"llama3instruct\",\n",
    "                \"llama3.1instruct\",\n",
    "                \"gemma9binstruct\",\n",
    "            ]\n",
    "        )\n",
    "    ].groupby(\n",
    "        [\"model\"]\n",
    "    )[\n",
    "        [\"perc_aya_data\", \"bias_mitigation\"]\n",
    "    ],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    debiasing_csp[debiasing_csp[\"bias_type\"] == \"overall\"][\n",
    "        debiasing_csp[\"dataset\"] == \"panda\"\n",
    "    ][\n",
    "        debiasing_csp[\"model\"].isin(\n",
    "            [\n",
    "                \"aya\",\n",
    "                \"ayaexpanse\",\n",
    "                \"llama3\",\n",
    "                \"llama3.1\",\n",
    "                \"gemma9b\",\n",
    "                \"llama3instruct\",\n",
    "                \"llama3.1instruct\",\n",
    "                \"gemma9binstruct\",\n",
    "            ]\n",
    "        )\n",
    "    ].groupby(\n",
    "        [\"model\"]\n",
    "    )[\n",
    "        [\"perc_cc_data\", \"bias_mitigation\"]\n",
    "    ],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4bf36",
   "metadata": {},
   "source": [
    "## Toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c24d08",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96844eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "detox = pd.merge(detox, df_lang_features, how=\"left\", on=\"language\")\n",
    "\n",
    "detox = pd.merge(detox, df_overlap, how=\"left\", on=[\"language\", \"model\", \"instruction\"])\n",
    "\n",
    "detox = pd.merge(\n",
    "    detox,\n",
    "    df_bi_sent_acc[df_bi_sent_acc[\"dataset\"] == \"rtp-lx\"].drop(columns=[\"dataset\"]),\n",
    "    how=\"left\",\n",
    "    on=[\"language\", \"model\", \"instruction\"],\n",
    ")\n",
    "\n",
    "detox = pd.merge(detox, aya_dataset, how=\"left\", on=\"language\")\n",
    "\n",
    "detox = pd.merge(detox, df_cc_perc, how=\"left\", on=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "detox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4780a",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    detox[detox[\"dataset\"]==\"detoxdpo\"].groupby([\"model\", \"feature_type\"])[[\"detoxification\", \"cos_sim\"]],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    detox[detox[\"dataset\"]==\"detoxdpo\"].groupby([\"model\"])[[\"detoxification\", \"overlap\"]],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdeb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    detox[detox[\"dataset\"]==\"detoxdpo\"].groupby([\"model\"])[[\"retrieval_acc\", \"detoxification\"]],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    detox[detox[\"dataset\"]==\"detoxdpo\"].groupby([\"model\"])[[\"perc_aya_data\", \"detoxification\"]],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09982e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_corr_with_p(\n",
    "    detox[detox[\"dataset\"]==\"detoxdpo\"].groupby([\"model\"])[[\"perc_cc_data\", \"detoxification\"]],\n",
    "    method=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0aac8c",
   "metadata": {},
   "source": [
    "# Data size analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_size = [\n",
    "    (\"Meta-Llama-3.1-8B-Instruct\", \"llama3.1instruct\", \"panda\", \"instruct\", 0, \"bias\"),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_2375\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        10,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_4750\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        20,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_7125\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        30,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_9500\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        40,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_11875\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        50,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_14250\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        60,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_16625\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        70,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_19000\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        80,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_21375\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        90,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_panda_model_23742\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"panda\",\n",
    "        \"instruct\",\n",
    "        100,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\"Meta-Llama-3.1-8B-Instruct\", \"llama3.1instruct\", \"biasdpo\", \"instruct\", 0, \"bias\"),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_542\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        10,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_1084\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        20,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_1626\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        30,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_2168\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        40,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_2710\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        50,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_3252\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        60,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_3794\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        70,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_4336\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        80,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_4878\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        90,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_biasdpo_model_5420\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"biasdpo\",\n",
    "        \"instruct\",\n",
    "        100,\n",
    "        \"bias\",\n",
    "    ),\n",
    "    (\"Meta-Llama-3.1-8B-Instruct\", \"llama3.1instruct\", \"jigsaw\", \"instruct\", 0, \"toxicity\"),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_2375\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        10,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_4750\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        20,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_7125\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        30,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_9500\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        40,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_11875\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        50,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_14250\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        60,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_16625\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        70,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_19000\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        80,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_21375\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        90,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_jigsaw_model_23742\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"jigsaw\",\n",
    "        \"instruct\",\n",
    "        100,\n",
    "        \"jigsaw\",\n",
    "    ),\n",
    "    (\"Meta-Llama-3.1-8B-Instruct\", \"llama3.1instruct\", \"detoxdpo\", \"instruct\", 0, \"toxicity\"),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_584\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        10,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_1168\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        20,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_1752\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        30,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_2336\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        40,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_2920\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        50,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_3504\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        60,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_4088\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        70,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_4672\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        80,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_5256\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        90,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "    (\n",
    "        \"Meta-Llama-3.1-8B-Instruct_lora_detoxdpo_model_5836\",\n",
    "        \"llama3.1instruct\",\n",
    "        \"detoxdpo\",\n",
    "        \"instruct\",\n",
    "        100,\n",
    "        \"toxicity\",\n",
    "    ),\n",
    "]\n",
    "sns.set(font_scale=1.75, style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e19db0",
   "metadata": {},
   "source": [
    "## StereoSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ec8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"en\": \"English\",\n",
    "    \"kr\": \"Korean\",\n",
    "}\n",
    "\n",
    "\n",
    "def dict_func():\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\": [],\n",
    "    \"language\": [],\n",
    "    \"ss_score\": [],\n",
    "    \"lm_score\": [],\n",
    "    \"bias_type\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    if task != \"bias\":\n",
    "        continue\n",
    "    for language in names:\n",
    "        with open(f\"stereoset/{model_name}_{language}_ssresults.pkl\", \"rb\") as infile:\n",
    "            score = pickle.load(infile)\n",
    "        for bias_type in [\"gender\", \"profession\", \"race\", \"religion\", \"overall\"]:\n",
    "            data[\"model\"].append(model)\n",
    "            #if data_perc != 0:\n",
    "            #    data[\"dataset\"].append(dataset + str(data_perc))\n",
    "            #else:\n",
    "            data[\"dataset\"].append(dataset)\n",
    "            data[\"instruction\"].append(instruct)\n",
    "            data[\"data_perc\"].append(data_perc)\n",
    "            data[\"language\"].append(names[language])\n",
    "            data[\"ss_score\"].append(score[\"intrasentence\"][bias_type][\"SS Score\"])\n",
    "            data[\"lm_score\"].append(score[\"intrasentence\"][bias_type][\"LM Score\"])\n",
    "            data[\"bias_type\"].append(bias_type)\n",
    "\n",
    "df_stereoset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stereoset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c982f77",
   "metadata": {},
   "source": [
    "## CrowSPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"zh\": \"Chinese\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac541f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\": [],\n",
    "    \"language\": [],\n",
    "    \"ss_score\": [],\n",
    "    \"n_samples\": [],\n",
    "    \"bias_type\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    if task != \"bias\":\n",
    "        continue\n",
    "    for language in names:\n",
    "        with open(f\"crowspairs/{model_name}_{language}_cspresults.pkl\", \"rb\") as infile:\n",
    "            score = pickle.load(infile)\n",
    "        for bias_type in [\n",
    "            \"race-color\",\n",
    "            \"socioeconomic\",\n",
    "            \"gender\",\n",
    "            \"disability\",\n",
    "            \"nationality\",\n",
    "            \"sexual-orientation\",\n",
    "            \"physical-appearance\",\n",
    "            \"religion\",\n",
    "            \"age\",\n",
    "        ]:\n",
    "            data[\"model\"].append(model)\n",
    "            #if data_perc != 0:\n",
    "            #    data[\"dataset\"].append(dataset + str(data_perc))\n",
    "            #else:\n",
    "            data[\"dataset\"].append(dataset)\n",
    "            data[\"instruction\"].append(instruct)\n",
    "            data[\"data_perc\"].append(data_perc)\n",
    "            data[\"language\"].append(names[language])\n",
    "            data[\"ss_score\"].append(score[bias_type][0])\n",
    "            data[\"n_samples\"].append(score[bias_type][1])\n",
    "            data[\"bias_type\"].append(bias_type)\n",
    "\n",
    "\n",
    "df_crowspairs = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323177bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = {\n",
    "    sorted(list(names.values()))[i]: df_crowspairs.groupby(\n",
    "        [\"model\", \"dataset\", \"instruction\", \"data_perc\", \"language\"]\n",
    "    )[\"n_samples\"]\n",
    "    .sum()\n",
    "    .values[i]\n",
    "    for i in range(len(list(names.values())))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc963f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\": [],\n",
    "    \"language\": [],\n",
    "    \"n_samples\": [],\n",
    "    \"ss_score\": [],\n",
    "    \"bias_type\": [],\n",
    "}\n",
    "for row in (\n",
    "    df_crowspairs.groupby([\"model\", \"dataset\", \"instruction\", \"data_perc\", \"language\"])\n",
    "    .apply(lambda x: np.average(x.ss_score, weights=x.n_samples))\n",
    "    .reset_index()\n",
    "    .iloc\n",
    "):\n",
    "    new_rows[\"model\"].append(row[\"model\"])\n",
    "    new_rows[\"dataset\"].append(row[\"dataset\"])\n",
    "    new_rows[\"instruction\"].append(row[\"instruction\"])\n",
    "    new_rows[\"data_perc\"].append(row[\"data_perc\"])\n",
    "    new_rows[\"language\"].append(row[\"language\"])\n",
    "    new_rows[\"n_samples\"].append(n_samples[row[\"language\"]])\n",
    "    new_rows[\"ss_score\"].append(row[0])\n",
    "    new_rows[\"bias_type\"].append(\"overall\")\n",
    "\n",
    "df_crowspairs = pd.concat(\n",
    "    [df_crowspairs, pd.DataFrame(data=new_rows)], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowspairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5805b62",
   "metadata": {},
   "source": [
    "## Bias plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias_results = df_stereoset.merge(\n",
    "    df_crowspairs,\n",
    "    on=[\"model\", \"dataset\", \"instruction\", \"data_perc\", \"language\", \"bias_type\", \"ss_score\"],\n",
    "    how=\"outer\",\n",
    "    indicator=\"bias_dataset\",\n",
    ").drop(columns=[\"lm_score\", \"n_samples\"])\n",
    "\n",
    "df_bias_results[\"bias_dataset\"] = df_bias_results[\"bias_dataset\"].cat.rename_categories(\n",
    "    {\"left_only\": \"stereoset\", \"right_only\": \"crowspairs\",}\n",
    ").cat.remove_categories([\"both\"])\n",
    "\n",
    "df_bias_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias_results[\"language\"][df_bias_results[\"language\"]!=\"English\"] = \"Non-English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a22e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Bias score\",\n",
    "    data=df_bias_results[df_bias_results[\"bias_type\"] == \"overall\"][\n",
    "        df_bias_results[\"dataset\"] == \"panda\"\n",
    "    ]\n",
    "    .replace({\"crowspairs\": \"CrowS-Pairs\", \"stereoset\": \"StereoSet\"})\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"ss_score\": \"Bias score\",\n",
    "            \"language\": \"Language\",\n",
    "            \"bias_dataset\": \"Dataset\",\n",
    "        }\n",
    "    ),\n",
    "    style=\"Language\",\n",
    "    hue=\"Dataset\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_bias_panda.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Bias score\",\n",
    "    data=df_bias_results[df_bias_results[\"bias_type\"] == \"overall\"][\n",
    "        df_bias_results[\"dataset\"] == \"biasdpo\"\n",
    "    ]\n",
    "    .replace({\"crowspairs\": \"CrowS-Pairs\", \"stereoset\": \"StereoSet\"})\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"ss_score\": \"Bias score\",\n",
    "            \"language\": \"Language\",\n",
    "            \"bias_dataset\": \"Dataset\",\n",
    "        }\n",
    "    ),\n",
    "    style=\"Language\",\n",
    "    hue=\"Dataset\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_bias_biasdpo.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5609e",
   "metadata": {},
   "source": [
    "## Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac57e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\": [],\n",
    "    \"language\": [],\n",
    "    \"emt\": [],\n",
    "    \"task\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    if task != \"toxicity\":\n",
    "        continue\n",
    "    for language in names:\n",
    "        with open(f\"toxicity/{model_name}_{language}_rtp-lx_lang.pkl\", \"rb\") as infile:\n",
    "            right_language = pickle.load(infile)\n",
    "        with open(\n",
    "            f\"toxicity/{model_name}_{language}_rtp-lx_tox_scores.pkl\", \"rb\"\n",
    "        ) as infile:\n",
    "            toxicity_scores = pickle.load(infile)\n",
    "        data[\"emt\"].append(\n",
    "            np.mean(\n",
    "                np.max(toxicity_scores, axis=1, where=right_language == 1, initial=0)\n",
    "            )\n",
    "        )\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"data_perc\"].append(data_perc)\n",
    "        data[\"language\"].append(names[language])\n",
    "        data[\"task\"].append(task)\n",
    "\n",
    "df_toxicity = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d3a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toxicity[\"language\"][df_toxicity[\"language\"]!=\"English\"] = \"Non-English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "tox_size = sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Toxicity score\",\n",
    "    data=df_toxicity[df_toxicity[\"dataset\"]==\"jigsaw\"].rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"emt\": \"Toxicity score\",\n",
    "            \"ss_score\": \"Bias score\",\n",
    "            \"language\": \"Language\",\n",
    "        }\n",
    "    ),\n",
    "    style=\"Language\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_tox_jigsaw.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "tox_size = sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Toxicity score\",\n",
    "    data=df_toxicity[df_toxicity[\"dataset\"] == \"detoxdpo\"].rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"emt\": \"Toxicity score\",\n",
    "            \"ss_score\": \"Bias score\",\n",
    "            \"language\": \"Language\",\n",
    "        }\n",
    "    ),\n",
    "    style=\"Language\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_tox_detoxdpo.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade8dc7",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = {}\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    with open(f\"perplexity/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    if dataset not in valid_ids:\n",
    "        valid_ids[dataset] = {}\n",
    "    for language in score:\n",
    "        ids = set(\n",
    "            [i for i, v in enumerate(score[language][\"selected\"]) if v != \"wrong_lang\"]\n",
    "        )\n",
    "        if language in valid_ids[dataset]:\n",
    "            valid_ids[dataset][language] = valid_ids[dataset][language].intersection(\n",
    "                ids\n",
    "            )\n",
    "        else:\n",
    "            valid_ids[dataset][language] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97572635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\": [],\n",
    "    \"language\": [],\n",
    "    \"perplexity\": [],\n",
    "    \"task\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    with open(f\"perplexity/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    for language in score:\n",
    "        if language == \"mt\":\n",
    "            num_sent = 65\n",
    "        else:\n",
    "            num_sent = 100\n",
    "        if len(valid_ids[dataset][language]) < num_sent:\n",
    "            continue\n",
    "        data[\"perplexity\"].append(\n",
    "            np.nanmedian(\n",
    "                [score[language][\"selected\"][i] for i in valid_ids[dataset][language]]\n",
    "            )\n",
    "        )\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"data_perc\"].append(data_perc)\n",
    "        data[\"language\"].append(names[language])\n",
    "        data[\"task\"].append(task)\n",
    "\n",
    "df_perplexity = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f07f0",
   "metadata": {},
   "source": [
    "## Language consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\":[],\n",
    "    \"language\": [],\n",
    "    \"lc_lpr\": [],\n",
    "    \"task\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    with open(f\"lang_confusion/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    for language in names:\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"data_perc\"].append(data_perc)\n",
    "        data[\"language\"].append(names[language])\n",
    "        data[\"lc_lpr\"].append(score[(\"tatoeba\", language)][\"lpr\"]*100)\n",
    "        data[\"task\"].append(task)\n",
    "\n",
    "df_lang_confusion = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b77a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lang_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb0a2e",
   "metadata": {},
   "source": [
    "## Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"mt\": \"Maltese\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e29e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = {}\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    with open(f\"diversity/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    if dataset not in valid_ids:\n",
    "        valid_ids[dataset] = {}\n",
    "    for language in score:\n",
    "        ids = set(\n",
    "            [i for i, v in enumerate(score[language][\"selected\"]) if v != \"wrong_lang\"]\n",
    "        )\n",
    "        if language in valid_ids[dataset]:\n",
    "            valid_ids[dataset][language] = valid_ids[dataset][language].intersection(\n",
    "                ids\n",
    "            )\n",
    "        else:\n",
    "            valid_ids[dataset][language] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46006cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\": [],\n",
    "    \"language\": [],\n",
    "    \"div_uni\": [],\n",
    "    \"task\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    with open(f\"diversity/{model_name}_results.pkl\", \"rb\") as infile:\n",
    "        score = pickle.load(infile)\n",
    "    for language in names:\n",
    "        if language == \"mt\":\n",
    "            num_sent = 65\n",
    "        else:\n",
    "            num_sent = 100\n",
    "        if len(valid_ids[dataset][language]) < num_sent:\n",
    "            continue\n",
    "        data[\"div_uni\"].append(\n",
    "            np.mean(\n",
    "                [score[language][\"selected\"][i] for i in valid_ids[dataset][language]]\n",
    "            )\n",
    "            * 100\n",
    "        )\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"data_perc\"].append(data_perc)\n",
    "        data[\"language\"].append(names[language])\n",
    "        data[\"task\"].append(task)\n",
    "\n",
    "df_diversity = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a52f534",
   "metadata": {},
   "source": [
    "## Global-MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a48819",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"de\": \"German\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"en\": \"English\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sv\": \"Swedish\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model\": [],\n",
    "    \"dataset\": [],\n",
    "    \"instruction\": [],\n",
    "    \"data_perc\": [],\n",
    "    \"language\": [],\n",
    "    \"acc\": [],\n",
    "    \"task\": [],\n",
    "}\n",
    "\n",
    "for model_name, model, dataset, instruct, data_perc, task in file_names_size:\n",
    "    for language in names:\n",
    "        for dirpath, dirnames, filenames in os.walk(\n",
    "            f\"global_mmlu/{model_name}_{language}\"\n",
    "        ):\n",
    "            if filenames:\n",
    "                file_name = filenames[0]\n",
    "                break\n",
    "        result = json.load(open(f\"{dirpath}/{file_name}\"))\n",
    "\n",
    "        data[\"model\"].append(model)\n",
    "        data[\"dataset\"].append(dataset)\n",
    "        data[\"instruction\"].append(instruct)\n",
    "        data[\"data_perc\"].append(data_perc)\n",
    "        data[\"language\"].append(names[language])\n",
    "        data[\"task\"].append(task)\n",
    "        data[\"acc\"].append(\n",
    "            result[\"results\"][f\"global_mmlu_full_{language}\"][\"acc,none\"] * 100\n",
    "        )\n",
    "\n",
    "df_global_mmlu = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b660220",
   "metadata": {},
   "source": [
    "## LM Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm_results = (\n",
    "    df_diversity.rename(columns={\"div_uni\": \"lm_score\"})\n",
    "    .merge(\n",
    "        df_lang_confusion.rename(\n",
    "            columns={\"lc_lpr\": \"lm_score\"}\n",
    "        ),\n",
    "        on=[\"model\", \"dataset\", \"instruction\", \"data_perc\", \"language\", \"task\",\"lm_score\"],\n",
    "        how=\"outer\",\n",
    "        indicator=\"lm_measure\",\n",
    "    )\n",
    ")\n",
    "\n",
    "df_lm_results[\"lm_measure\"] = df_lm_results[\"lm_measure\"].cat.rename_categories(\n",
    "    {\"left_only\": \"diversity\", \"right_only\": \"language consistency\"}\n",
    ")\n",
    "\n",
    "df_perplexity_updated = df_perplexity.rename(columns={\"perplexity\": \"lm_score\"})\n",
    "df_perplexity_updated.insert(\n",
    "    len(df_perplexity_updated.columns), \"lm_measure\", \"perplexity\"\n",
    ")\n",
    "\n",
    "df_lm_results = df_lm_results.merge(\n",
    "    df_perplexity_updated,\n",
    "    on=[\"model\", \"dataset\", \"instruction\", \"data_perc\", \"language\", \"task\", \"lm_score\", \"lm_measure\"],\n",
    "    how=\"outer\",\n",
    ")\n",
    "\n",
    "df_global_mmlu_updated = df_global_mmlu.rename(columns={\"acc\": \"lm_score\"})\n",
    "df_global_mmlu_updated.insert(\n",
    "    len(df_global_mmlu_updated.columns), \"lm_measure\", \"language understanding\"\n",
    ")\n",
    "df_lm_results = df_lm_results.merge(\n",
    "    df_global_mmlu_updated,\n",
    "    on=[\"model\", \"dataset\", \"instruction\", \"data_perc\", \"language\", \"task\", \"lm_score\", \"lm_measure\"],\n",
    "    how=\"outer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d0be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm_results[\"language\"][df_lm_results[\"language\"]!=\"English\"] = \"Non-English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "div_size = sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Score\",\n",
    "    data=df_lm_results[df_lm_results[\"dataset\"] == \"panda\"]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"lm_score\": \"Score\",\n",
    "            \"language\": \"Language\",\n",
    "            \"lm_measure\": \"Property\",\n",
    "        }\n",
    "    )\n",
    "    .replace(\n",
    "        {\n",
    "            \"diversity\": \"Diversity\",\n",
    "            \"perplexity\": \"Perplexity\",\n",
    "            \"language consistency\": \"Language\\nconsistency\",\n",
    "            \"language understanding\": \"Question-\\nanswering\",\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=\"Property\"),\n",
    "    hue=\"Property\",\n",
    "    style=\"Language\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_lm_panda.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "div_size = sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Score\",\n",
    "    data=df_lm_results[df_lm_results[\"dataset\"] == \"biasdpo\"]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"lm_score\": \"Score\",\n",
    "            \"language\": \"Language\",\n",
    "            \"lm_measure\": \"Property\",\n",
    "        }\n",
    "    )\n",
    "    .replace(\n",
    "        {\n",
    "            \"diversity\": \"Diversity\",\n",
    "            \"perplexity\": \"Perplexity\",\n",
    "            \"language consistency\": \"Language\\nconsistency\",\n",
    "            \"language understanding\": \"Question-\\nanswering\",\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=\"Property\"),\n",
    "    hue=\"Property\",\n",
    "    style=\"Language\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_lm_biasdpo.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae41fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "div_size = sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Score\",\n",
    "    data=df_lm_results[df_lm_results[\"dataset\"] == \"jigsaw\"]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"lm_score\": \"Score\",\n",
    "            \"language\": \"Language\",\n",
    "            \"lm_measure\": \"Property\",\n",
    "        }\n",
    "    )\n",
    "    .replace(\n",
    "        {\n",
    "            \"diversity\": \"Diversity\",\n",
    "            \"perplexity\": \"Perplexity\",\n",
    "            \"language consistency\": \"Language\\nconsistency\",\n",
    "            \"language understanding\": \"Question-\\nanswering\",\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=\"Property\"),\n",
    "    hue=\"Property\",\n",
    "    style=\"Language\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_lm_jigsaw.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "div_size = sns.lineplot(\n",
    "    x=\"Percentage of training\",\n",
    "    y=\"Score\",\n",
    "    data=df_lm_results[df_lm_results[\"dataset\"] == \"detoxdpo\"]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"data_perc\": \"Percentage of training\",\n",
    "            \"lm_score\": \"Score\",\n",
    "            \"language\": \"Language\",\n",
    "            \"lm_measure\": \"Property\",\n",
    "        }\n",
    "    )\n",
    "    .replace(\n",
    "        {\n",
    "            \"diversity\": \"Diversity\",\n",
    "            \"perplexity\": \"Perplexity\",\n",
    "            \"language consistency\": \"Language\\nconsistency\",\n",
    "            \"language understanding\": \"Question-\\nanswering\",\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=\"Property\"),\n",
    "    hue=\"Property\",\n",
    "    style=\"Language\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "fig.savefig(\"figures/size_lm_detoxdpo.pdf\", dpi=100, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "561px",
    "width": "370px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
